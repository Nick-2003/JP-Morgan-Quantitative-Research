{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 5: Putting it all together \n",
    "### Associated lectures: All material till lecture 11\n",
    "\n",
    "**See PrairieLearn for _due date_ and _submission_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Submission instructions <a name=\"si\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 4_\n",
    "\n",
    "You will receive marks for correctly submitting this assignment. To submit this assignment, follow the instructions below:\n",
    "\n",
    "- **You may work on this assignment in a group (group size <= 4) and submit your assignment as a group.** \n",
    "- Below are some instructions on working as a group.  \n",
    "    - The maximum group size is 4.\n",
    "    - You can choose your own group members. \n",
    "    - Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "    - Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "    - It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- Be sure to follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2024s/blob/main/docs/homework_instructions.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import string\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import tests_hw5\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"in\"></a>\n",
    "\n",
    "In this homework you will be working on an open-ended mini-project, where you will put all the different things you have learned so far together to solve an interesting problem.\n",
    "\n",
    "A few notes and tips when you work on this mini-project: \n",
    "\n",
    "#### Tips\n",
    "1. This mini-project is open-ended, and while working on it, there might be some situations where you'll have to use your own judgment and make your own decisions (as you would be doing when you work as a data scientist). Make sure you explain your decisions whenever necessary. \n",
    "2. **Do not include everything you ever tried in your submission** -- it's fine just to have your final code. That said, your code should be reproducible and well-documented. For example, if you chose your hyperparameters based on some hyperparameter optimization experiment, you should leave in the code for that experiment so that someone else could re-run it and obtain the same hyperparameters, rather than mysteriously just setting the hyperparameters to some (carefully chosen) values in your code. \n",
    "3. If you realize that you are repeating a lot of code try to organize it in functions. Clear presentation of your code, experiments, and results is the key to be successful in this lab. You may use code from lecture notes or previous lab solutions with appropriate attributions. \n",
    "\n",
    "#### Assessment\n",
    "We plan to grade fairly and leniently. We don't have some secret target score that you need to achieve to get a good grade. **You'll be assessed on demonstration of mastery of course topics, clear presentation, and the quality of your analysis and results.** For example, if you just have a bunch of code and no text or figures, that's not good. If you do a bunch of sane things and get a lower accuracy than your friend, don't sweat it.\n",
    "\n",
    "\n",
    "#### A final note\n",
    "Finally, this style of this \"project\" question is different from other assignments. It'll be up to you to decide when you're \"done\" -- in fact, this is one of the hardest parts of real projects. But please don't spend WAY too much time on this... perhaps \"a few hours\". Of course if you're having fun you're welcome to spend as much time as you want! But, if so, try not to do it out of perfectionism or getting the best possible grade. Do it because you're learning and enjoying it. Students from the past cohorts have found such kind of labs useful and fun and I hope you enjoy it as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 1. Pick your problem and explain the prediction problem <a name=\"1\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 3_\n",
    "\n",
    "In this mini project, you will be working on a classification problem of predicting whether a credit card client will default or not. \n",
    "For this problem, you will use [Default of Credit Card Clients Dataset](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset). In this data set, there are 30,000 examples and 24 features, and the goal is to estimate whether a person will default (fail to pay) their credit card bills; this column is labeled \"default.payment.next.month\" in the data. The rest of the columns can be used as features. You may take some ideas and compare your results with [the associated research paper](https://www.sciencedirect.com/science/article/pii/S0957417407006719), which is available through [the UBC library](https://www.library.ubc.ca/). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Spend some time understanding the problem and what each feature means. You can find this information in the documentation on [the dataset page on Kaggle](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset). Write a few sentences on your initial thoughts on the problem and the dataset. \n",
    "2. Download the dataset and read it as a pandas dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/uciml/default-of-credit-card-clients-dataset/discussion/34608\n",
    "\n",
    "The dataset has 30000 observations, and thus has minimal risk of models overfitting to the data. The columns `SEX`, `EDUCATION`, `MARRIAGE`, `PAY_0`, `PAY_2`, `PAY_3`, `PAY_4`, `PAY_5`, and `PAY_6` are categorical variables, not numerical, and thus will need to be adjusted as such. However, `SEX`, `EDUCATION`, and `MARRIAGE` appear to be less directly relevant to the prediction of default payment, and thus could be considered for being dropped. Due to the differing ranges for each numeric column, each of them will need to be standardised for more effective interpretation of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>220000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88004.0</td>\n",
       "      <td>31237.0</td>\n",
       "      <td>15980.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>5003.0</td>\n",
       "      <td>3047.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8979.0</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>3526.0</td>\n",
       "      <td>8998.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20878.0</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>19357.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52774.0</td>\n",
       "      <td>11855.0</td>\n",
       "      <td>48944.0</td>\n",
       "      <td>85900.0</td>\n",
       "      <td>3409.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>52964.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30000</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36535.0</td>\n",
       "      <td>32428.0</td>\n",
       "      <td>15313.0</td>\n",
       "      <td>2078.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "ID                                                                            \n",
       "1        20000.0    2          2         1   24      2      2     -1     -1   \n",
       "2       120000.0    2          2         2   26     -1      2      0      0   \n",
       "3        90000.0    2          2         2   34      0      0      0      0   \n",
       "4        50000.0    2          2         1   37      0      0      0      0   \n",
       "5        50000.0    1          2         1   57     -1      0     -1      0   \n",
       "...          ...  ...        ...       ...  ...    ...    ...    ...    ...   \n",
       "29996   220000.0    1          3         1   39      0      0      0      0   \n",
       "29997   150000.0    1          3         2   43     -1     -1     -1     -1   \n",
       "29998    30000.0    1          2         2   37      4      3      2     -1   \n",
       "29999    80000.0    1          3         1   41      1     -1      0      0   \n",
       "30000    50000.0    1          2         1   46      0      0      0      0   \n",
       "\n",
       "       PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "ID            ...                                                        \n",
       "1         -2  ...        0.0        0.0        0.0       0.0     689.0   \n",
       "2          0  ...     3272.0     3455.0     3261.0       0.0    1000.0   \n",
       "3          0  ...    14331.0    14948.0    15549.0    1518.0    1500.0   \n",
       "4          0  ...    28314.0    28959.0    29547.0    2000.0    2019.0   \n",
       "5          0  ...    20940.0    19146.0    19131.0    2000.0   36681.0   \n",
       "...      ...  ...        ...        ...        ...       ...       ...   \n",
       "29996      0  ...    88004.0    31237.0    15980.0    8500.0   20000.0   \n",
       "29997      0  ...     8979.0     5190.0        0.0    1837.0    3526.0   \n",
       "29998      0  ...    20878.0    20582.0    19357.0       0.0       0.0   \n",
       "29999      0  ...    52774.0    11855.0    48944.0   85900.0    3409.0   \n",
       "30000      0  ...    36535.0    32428.0    15313.0    2078.0    1800.0   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "ID                                                                         \n",
       "1           0.0       0.0       0.0       0.0                           1  \n",
       "2        1000.0    1000.0       0.0    2000.0                           1  \n",
       "3        1000.0    1000.0    1000.0    5000.0                           0  \n",
       "4        1200.0    1100.0    1069.0    1000.0                           0  \n",
       "5       10000.0    9000.0     689.0     679.0                           0  \n",
       "...         ...       ...       ...       ...                         ...  \n",
       "29996    5003.0    3047.0    5000.0    1000.0                           0  \n",
       "29997    8998.0     129.0       0.0       0.0                           0  \n",
       "29998   22000.0    4200.0    2000.0    3100.0                           1  \n",
       "29999    1178.0    1926.0   52964.0    1804.0                           1  \n",
       "30000    1430.0    1000.0    1000.0    1000.0                           1  \n",
       "\n",
       "[30000 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_df = pd.read_csv(\"data/UCI_Credit_Card.csv\", index_col = 0)\n",
    "credit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 2. Data splitting <a name=\"2\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 2_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train (70%) and test (30%) portions with `random_state=76`.\n",
    "\n",
    "> If your computer cannot handle training on 70% training data, make the test split bigger.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8959</th>\n",
       "      <td>340000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>59324.0</td>\n",
       "      <td>156094.0</td>\n",
       "      <td>110234.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>4234.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22753</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>171700.0</td>\n",
       "      <td>5504.0</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>173026.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25883</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75443.0</td>\n",
       "      <td>57735.0</td>\n",
       "      <td>58139.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12926</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>79295.0</td>\n",
       "      <td>81142.0</td>\n",
       "      <td>80672.0</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>3107.0</td>\n",
       "      <td>2847.0</td>\n",
       "      <td>3134.0</td>\n",
       "      <td>3072.0</td>\n",
       "      <td>3010.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23599</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>9628.0</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>32194.0</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>9628.0</td>\n",
       "      <td>16059.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22811</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>7306.0</td>\n",
       "      <td>18726.0</td>\n",
       "      <td>13839.0</td>\n",
       "      <td>6151.0</td>\n",
       "      <td>6427.0</td>\n",
       "      <td>7306.0</td>\n",
       "      <td>18738.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7154.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6529</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>42726.0</td>\n",
       "      <td>43802.0</td>\n",
       "      <td>42761.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>1737.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>5050.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9608</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>303.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3723.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12280</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>2862.0</td>\n",
       "      <td>5539.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>2862.0</td>\n",
       "      <td>5539.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5775.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38712.0</td>\n",
       "      <td>39304.0</td>\n",
       "      <td>40479.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2716.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "ID                                                                            \n",
       "8959    340000.0    1          1         2   44      0      0      0      0   \n",
       "22753   200000.0    2          2         2   34      0      0      0     -1   \n",
       "25883    80000.0    2          2         1   26      0      0      0      0   \n",
       "12926    80000.0    2          2         1   45      0      0      0      0   \n",
       "23599    80000.0    2          2         1   40     -1     -1     -1     -1   \n",
       "...          ...  ...        ...       ...  ...    ...    ...    ...    ...   \n",
       "22811   150000.0    2          3         1   42     -1     -1     -1     -1   \n",
       "6529     90000.0    2          5         2   23      0      0      0      0   \n",
       "9608     80000.0    2          1         1   35     -1      2     -1     -1   \n",
       "12280    80000.0    2          2         1   27     -1     -1     -1     -1   \n",
       "2722    100000.0    2          1         2   33      0      0      0      0   \n",
       "\n",
       "       PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "ID            ...                                                        \n",
       "8959       0  ...    59324.0   156094.0   110234.0   20000.0    5000.0   \n",
       "22753     -1  ...     1078.0     1598.0   171700.0    5504.0    1526.0   \n",
       "25883      0  ...    75443.0    57735.0    58139.0    2800.0    2800.0   \n",
       "12926      0  ...    79295.0    81142.0    80672.0    3130.0    3107.0   \n",
       "23599     -1  ...     1729.0      590.0     9628.0    2035.0   32194.0   \n",
       "...      ...  ...        ...        ...        ...       ...       ...   \n",
       "22811     -1  ...     7306.0    18726.0    13839.0    6151.0    6427.0   \n",
       "6529       0  ...    42726.0    43802.0    42761.0    2000.0    2000.0   \n",
       "9608      -1  ...      303.0      662.0     3295.0       0.0    3723.0   \n",
       "12280     -1  ...     2862.0     5539.0        0.0       0.0     680.0   \n",
       "2722       0  ...    38712.0    39304.0    40479.0    2000.0    5000.0   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "ID                                                                         \n",
       "8959     2000.0  112000.0    4234.0    4000.0                           1  \n",
       "22753    1078.0    1598.0  173026.0    6000.0                           0  \n",
       "25883    2400.0    2100.0    2100.0    2100.0                           0  \n",
       "12926    2847.0    3134.0    3072.0    3010.0                           0  \n",
       "23599    1729.0     590.0    9628.0   16059.0                           0  \n",
       "...         ...       ...       ...       ...                         ...  \n",
       "22811    7306.0   18738.0       0.0    7154.0                           0  \n",
       "6529     1502.0    1737.0    1500.0    5050.0                           1  \n",
       "9608      891.0     662.0    3295.0    1088.0                           0  \n",
       "12280    2862.0    5539.0       0.0    5775.0                           0  \n",
       "2722     1521.0    1595.0    2000.0    2716.0                           0  \n",
       "\n",
       "[21000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(credit_df, test_size=0.3, random_state=76)\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 3. EDA <a name=\"3\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 10_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Perform exploratory data analysis on the train set.\n",
    "2. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n",
    "3. Summarize your initial observations about the data. \n",
    "4. Pick appropriate metric/metrics for assessment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) \n",
    "\n",
    "`.describe()`: There are mean values for `SEX`, `EDUCATION`, `MARRIAGE`, the repayment statuses `PAY_0` to `PAY_6`, and `default.payment.next.month`, despite them being categorical variables, and thus should be accounted for later on. The ranges for the numerical variables `LIMIT_BAL`, `AGE`, `BILL_AMT1`, `BILL_AMT2`, `BILL_AMT3`, `BILL_AMT4`, `BILL_AMT5`, `BILL_AMT6`, `PAY_AMT1`, `PAY_AMT2`, `PAY_AMT3`, `PAY_AMT4`, `PAY_AMT5`, `PAY_AMT6` are not in the same scale, such as `LIMIT_BAL` having a range of [10000, 1000000], and `PAY_AMT6` having a range of [0, 528666], and thus should be scaled. \n",
    "\n",
    "`.info()` and `.isna().any()`: There are no missing values within the dataset. According to `Dtype`, all of the categorical variables are treated as integer values. \n",
    "\n",
    "`.value_counts(normalize=True)`: The class distribution is imbalanced, with `default.payment.next.month = 0` having a proportion of 0.778143, and `default.payment.next.month = 1` having a proportion of 0.221857. \n",
    "\n",
    "Categories in categorical columns: This was done to display what potential values could be found within the dataset. Notably, `EDUCATION` has unknown values 0, 5, and 6. \n",
    "\n",
    "Histograms: Both `LIMIT_BAL` and `AGE` have significantly different distributions for each category, implying that they are relevant to the prediction task.\n",
    "\n",
    "Bar plots: The bar plots display imbalanced class distributions for each categorical variable `SEX`, `EDUCATION`, and `MARRIAGE`, and there are unknown values found within the `EDUCATION` barplot. Specifically, `EDUCATION` has unknown values 0, 5, and 6.\n",
    "\n",
    "(3) \n",
    "\n",
    "A `FunctionTransformer()` will be required to convert the data type for the categorical variables to string. The numerical variables should be scaled with a `StandardScaler()`. `PAY_AMT1`, `PAY_AMT2`, `PAY_AMT3`, `PAY_AMT4`, `PAY_AMT5`, `PAY_AMT6` all share the same ordinal scale and thus can be grouped accordingly. None of the data is missing, and thus imputation is not required. The unknown values within `EDUCATION` will be grouped together into an \"other\" category if possible. \n",
    "\n",
    "(4) \n",
    "\n",
    "https://graphite-note.com/understanding-the-importance-of-f1-score-in-machine-learning-3/#:~:text=F1%20Score%20in%20Imbalanced%20Datasets&text=The%20F1%20score%20provides%20a%20more%20robust%20evaluation%20metric%2C%20especially,performance%20despite%20the%20class%20imbalance. \n",
    "\n",
    "Given the class imbalance in `default.payment.next.month`, then F1-score would be an appropriate metric for this assignment, as F1-score provides fair representations of model performance in spite of class imbalance. As such, F1-score will be our metric of focus for our hyperparameter optimisations. For the sake of prudence, precision and recall will also be included in our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>2.100000e+04</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>167563.508571</td>\n",
       "      <td>1.604381</td>\n",
       "      <td>1.843905</td>\n",
       "      <td>1.554667</td>\n",
       "      <td>35.412952</td>\n",
       "      <td>-0.012190</td>\n",
       "      <td>-0.132714</td>\n",
       "      <td>-0.168333</td>\n",
       "      <td>-0.223143</td>\n",
       "      <td>-0.265762</td>\n",
       "      <td>...</td>\n",
       "      <td>43039.813952</td>\n",
       "      <td>40121.889810</td>\n",
       "      <td>38623.497095</td>\n",
       "      <td>5601.265286</td>\n",
       "      <td>6.059441e+03</td>\n",
       "      <td>5204.302571</td>\n",
       "      <td>4889.281333</td>\n",
       "      <td>4782.900857</td>\n",
       "      <td>5162.918714</td>\n",
       "      <td>0.221857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>129919.112502</td>\n",
       "      <td>0.488995</td>\n",
       "      <td>0.789845</td>\n",
       "      <td>0.521970</td>\n",
       "      <td>9.136302</td>\n",
       "      <td>1.121864</td>\n",
       "      <td>1.196554</td>\n",
       "      <td>1.195375</td>\n",
       "      <td>1.165490</td>\n",
       "      <td>1.134210</td>\n",
       "      <td>...</td>\n",
       "      <td>63817.414980</td>\n",
       "      <td>60400.798292</td>\n",
       "      <td>59055.005208</td>\n",
       "      <td>16239.423781</td>\n",
       "      <td>2.407470e+04</td>\n",
       "      <td>16865.645456</td>\n",
       "      <td>16486.840852</td>\n",
       "      <td>15431.523094</td>\n",
       "      <td>17170.608569</td>\n",
       "      <td>0.415505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-170000.000000</td>\n",
       "      <td>-81334.000000</td>\n",
       "      <td>-209051.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>1266.250000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.200000e+02</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>257.750000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>140000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18990.000000</td>\n",
       "      <td>18091.000000</td>\n",
       "      <td>17127.000000</td>\n",
       "      <td>2112.500000</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1801.500000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>240000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54740.000000</td>\n",
       "      <td>50065.250000</td>\n",
       "      <td>48950.500000</td>\n",
       "      <td>5012.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4531.250000</td>\n",
       "      <td>4048.500000</td>\n",
       "      <td>4078.000000</td>\n",
       "      <td>4001.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>800000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>706864.000000</td>\n",
       "      <td>823540.000000</td>\n",
       "      <td>568638.000000</td>\n",
       "      <td>873552.000000</td>\n",
       "      <td>1.684259e+06</td>\n",
       "      <td>889043.000000</td>\n",
       "      <td>621000.000000</td>\n",
       "      <td>426529.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           LIMIT_BAL           SEX     EDUCATION      MARRIAGE           AGE  \\\n",
       "count   21000.000000  21000.000000  21000.000000  21000.000000  21000.000000   \n",
       "mean   167563.508571      1.604381      1.843905      1.554667     35.412952   \n",
       "std    129919.112502      0.488995      0.789845      0.521970      9.136302   \n",
       "min     10000.000000      1.000000      0.000000      0.000000     21.000000   \n",
       "25%     50000.000000      1.000000      1.000000      1.000000     28.000000   \n",
       "50%    140000.000000      2.000000      2.000000      2.000000     34.000000   \n",
       "75%    240000.000000      2.000000      2.000000      2.000000     41.000000   \n",
       "max    800000.000000      2.000000      6.000000      3.000000     79.000000   \n",
       "\n",
       "              PAY_0         PAY_2         PAY_3         PAY_4         PAY_5  \\\n",
       "count  21000.000000  21000.000000  21000.000000  21000.000000  21000.000000   \n",
       "mean      -0.012190     -0.132714     -0.168333     -0.223143     -0.265762   \n",
       "std        1.121864      1.196554      1.195375      1.165490      1.134210   \n",
       "min       -2.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
       "25%       -1.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        8.000000      8.000000      8.000000      8.000000      8.000000   \n",
       "\n",
       "       ...      BILL_AMT4      BILL_AMT5      BILL_AMT6       PAY_AMT1  \\\n",
       "count  ...   21000.000000   21000.000000   21000.000000   21000.000000   \n",
       "mean   ...   43039.813952   40121.889810   38623.497095    5601.265286   \n",
       "std    ...   63817.414980   60400.798292   59055.005208   16239.423781   \n",
       "min    ... -170000.000000  -81334.000000 -209051.000000       0.000000   \n",
       "25%    ...    2300.000000    1800.000000    1266.250000    1000.000000   \n",
       "50%    ...   18990.000000   18091.000000   17127.000000    2112.500000   \n",
       "75%    ...   54740.000000   50065.250000   48950.500000    5012.000000   \n",
       "max    ...  706864.000000  823540.000000  568638.000000  873552.000000   \n",
       "\n",
       "           PAY_AMT2       PAY_AMT3       PAY_AMT4       PAY_AMT5  \\\n",
       "count  2.100000e+04   21000.000000   21000.000000   21000.000000   \n",
       "mean   6.059441e+03    5204.302571    4889.281333    4782.900857   \n",
       "std    2.407470e+04   16865.645456   16486.840852   15431.523094   \n",
       "min    0.000000e+00       0.000000       0.000000       0.000000   \n",
       "25%    8.200000e+02     390.000000     291.000000     257.750000   \n",
       "50%    2.009000e+03    1801.500000    1500.000000    1500.000000   \n",
       "75%    5.000000e+03    4531.250000    4048.500000    4078.000000   \n",
       "max    1.684259e+06  889043.000000  621000.000000  426529.000000   \n",
       "\n",
       "            PAY_AMT6  default.payment.next.month  \n",
       "count   21000.000000                21000.000000  \n",
       "mean     5162.918714                    0.221857  \n",
       "std     17170.608569                    0.415505  \n",
       "min         0.000000                    0.000000  \n",
       "25%       150.000000                    0.000000  \n",
       "50%      1500.000000                    0.000000  \n",
       "75%      4001.000000                    0.000000  \n",
       "max    528666.000000                    1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21000 entries, 8959 to 2722\n",
      "Data columns (total 24 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   LIMIT_BAL                   21000 non-null  float64\n",
      " 1   SEX                         21000 non-null  int64  \n",
      " 2   EDUCATION                   21000 non-null  int64  \n",
      " 3   MARRIAGE                    21000 non-null  int64  \n",
      " 4   AGE                         21000 non-null  int64  \n",
      " 5   PAY_0                       21000 non-null  int64  \n",
      " 6   PAY_2                       21000 non-null  int64  \n",
      " 7   PAY_3                       21000 non-null  int64  \n",
      " 8   PAY_4                       21000 non-null  int64  \n",
      " 9   PAY_5                       21000 non-null  int64  \n",
      " 10  PAY_6                       21000 non-null  int64  \n",
      " 11  BILL_AMT1                   21000 non-null  float64\n",
      " 12  BILL_AMT2                   21000 non-null  float64\n",
      " 13  BILL_AMT3                   21000 non-null  float64\n",
      " 14  BILL_AMT4                   21000 non-null  float64\n",
      " 15  BILL_AMT5                   21000 non-null  float64\n",
      " 16  BILL_AMT6                   21000 non-null  float64\n",
      " 17  PAY_AMT1                    21000 non-null  float64\n",
      " 18  PAY_AMT2                    21000 non-null  float64\n",
      " 19  PAY_AMT3                    21000 non-null  float64\n",
      " 20  PAY_AMT4                    21000 non-null  float64\n",
      " 21  PAY_AMT5                    21000 non-null  float64\n",
      " 22  PAY_AMT6                    21000 non-null  float64\n",
      " 23  default.payment.next.month  21000 non-null  int64  \n",
      "dtypes: float64(13), int64(11)\n",
      "memory usage: 4.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LIMIT_BAL                     False\n",
       "SEX                           False\n",
       "EDUCATION                     False\n",
       "MARRIAGE                      False\n",
       "AGE                           False\n",
       "PAY_0                         False\n",
       "PAY_2                         False\n",
       "PAY_3                         False\n",
       "PAY_4                         False\n",
       "PAY_5                         False\n",
       "PAY_6                         False\n",
       "BILL_AMT1                     False\n",
       "BILL_AMT2                     False\n",
       "BILL_AMT3                     False\n",
       "BILL_AMT4                     False\n",
       "BILL_AMT5                     False\n",
       "BILL_AMT6                     False\n",
       "PAY_AMT1                      False\n",
       "PAY_AMT2                      False\n",
       "PAY_AMT3                      False\n",
       "PAY_AMT4                      False\n",
       "PAY_AMT5                      False\n",
       "PAY_AMT6                      False\n",
       "default.payment.next.month    False\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "default.payment.next.month\n",
       "0    0.778143\n",
       "1    0.221857\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories in SEX: [1 2]\n",
      "Categories in EDUCATION: [1 2 3 5 4 6 0]\n",
      "Categories in MARRIAGE: [2 1 3 0]\n",
      "Categories in PAY_0: [ 0 -1  2  1 -2  3  4  5  8  6  7]\n",
      "Categories in PAY_2: [ 0 -1  2 -2  3  4  1  6  5  7  8]\n",
      "Categories in PAY_3: [ 0 -1  2 -2  3  4  5  7  6  1  8]\n",
      "Categories in PAY_4: [ 0 -1 -2  2  4  7  5  3  6  8]\n",
      "Categories in PAY_5: [ 0 -1 -2  2  3  7  5  4  6  8]\n",
      "Categories in PAY_6: [ 0 -1 -2  2  6  3  7  4  5  8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Describe dataset \n",
    "display(train_df.describe()) \n",
    "\n",
    "# General info for dataset \n",
    "display(train_df.info())\n",
    "\n",
    "# Presence of NaN \n",
    "# https://stackoverflow.com/questions/36226083/how-to-find-which-columns-contain-any-nan-value-in-pandas-dataframe\n",
    "display(train_df.isna().any())\n",
    "\n",
    "# Check if class distribution is balanced (Adapted from Lecture 10)\n",
    "display(train_df[\"default.payment.next.month\"].value_counts(normalize=True))\n",
    "\n",
    "# Categories in categorical columns\n",
    "# https://stackoverflow.com/questions/27241253/print-the-unique-values-in-every-column-in-a-pandas-dataframe\n",
    "categorical_cols = [\"SEX\", \"EDUCATION\", \"MARRIAGE\", \"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\",]\n",
    "for col in categorical_cols:\n",
    "    print(\"Categories in \" + str(col) + \": \" + str(train_df[col].unique()))\n",
    "\n",
    "# numeric_cols = [\"LIMIT_BAL\", \"AGE\", \"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\", \"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\",]\n",
    "# for col in numeric_cols: \n",
    "#     print(\"Count of values in \" + str(col) + \": \" + str(len(train_df[col].unique())))\n",
    "\n",
    "# Histograms for numeric columns (Adapted from HW3)\n",
    "# numeric_cols = [\"LIMIT_BAL\", \"AGE\", \"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\", \"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\",]\n",
    "# for f in numeric_cols: \n",
    "# for f in [\"LIMIT_BAL\", \"AGE\"]:\n",
    "#     ax = train_df.groupby(\"default.payment.next.month\")[f].plot.hist(alpha = 0.5, bins = 27, legend = True, density = True)\n",
    "#     plt.xlabel(f)\n",
    "#     plt.title(\"Histogram of \" + f)\n",
    "#     plt.show()\n",
    "\n",
    "# https://stackoverflow.com/questions/17523545/pandas-histogram-with-fixed-width\n",
    "ax1 = train_df.groupby(\"default.payment.next.month\")[\"LIMIT_BAL\"].plot.hist(alpha = 0.5, bins = range(0, 800000, 10000), legend = True, density = True)\n",
    "plt.xlabel(\"LIMIT_BAL\")\n",
    "plt.title(\"Histogram of LIMIT_BAL\")\n",
    "plt.show()\n",
    "\n",
    "ax2 = train_df.groupby(\"default.payment.next.month\")[\"AGE\"].plot.hist(alpha = 0.5, bins = range(21,79), legend = True, density = True)\n",
    "plt.xlabel(\"AGE\")\n",
    "plt.title(\"Histogram of AGE\")\n",
    "plt.show()\n",
    "\n",
    "# Bar plots for categorical columns \n",
    "# https://www.geeksforgeeks.org/plotting-multiple-bar-charts-using-matplotlib-in-python/\n",
    "# https://stackoverflow.com/questions/39135472/setting-order-of-columns-with-matplotlib-bar-chart\n",
    "# categorical_cols = [\"SEX\", \"EDUCATION\", \"MARRIAGE\", \"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\",]\n",
    "# for f in categorical_cols:\n",
    "# for f in [\"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\",]:\n",
    "for f in [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]:\n",
    "    frame = train_df[f].astype(\"string\")\n",
    "    f_cats = frame.value_counts().sort_index()\n",
    "    plt.bar(f_cats.index, f_cats)\n",
    "    plt.xlabel(f)\n",
    "    plt.title(\"Bar plot of \" + f) \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8959</th>\n",
       "      <td>340000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73950.0</td>\n",
       "      <td>59324.0</td>\n",
       "      <td>156094.0</td>\n",
       "      <td>110234.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>4234.0</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22753</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>171700.0</td>\n",
       "      <td>5504.0</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>173026.0</td>\n",
       "      <td>6000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25883</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>74349.0</td>\n",
       "      <td>75443.0</td>\n",
       "      <td>57735.0</td>\n",
       "      <td>58139.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12926</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>80966.0</td>\n",
       "      <td>79295.0</td>\n",
       "      <td>81142.0</td>\n",
       "      <td>80672.0</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>3107.0</td>\n",
       "      <td>2847.0</td>\n",
       "      <td>3134.0</td>\n",
       "      <td>3072.0</td>\n",
       "      <td>3010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23599</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>32194.0</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>9628.0</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>32194.0</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>9628.0</td>\n",
       "      <td>16059.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "ID                                                                            \n",
       "8959    340000.0    1          1         2   44      0      0      0      0   \n",
       "22753   200000.0    2          2         2   34      0      0      0     -1   \n",
       "25883    80000.0    2          2         1   26      0      0      0      0   \n",
       "12926    80000.0    2          2         1   45      0      0      0      0   \n",
       "23599    80000.0    2          2         1   40     -1     -1     -1     -1   \n",
       "\n",
       "       PAY_5  ...  BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  \\\n",
       "ID            ...                                                         \n",
       "8959       0  ...    73950.0    59324.0   156094.0   110234.0   20000.0   \n",
       "22753     -1  ...     3455.0     1078.0     1598.0   171700.0    5504.0   \n",
       "25883      0  ...    74349.0    75443.0    57735.0    58139.0    2800.0   \n",
       "12926      0  ...    80966.0    79295.0    81142.0    80672.0    3130.0   \n",
       "23599     -1  ...    32194.0     1729.0      590.0     9628.0    2035.0   \n",
       "\n",
       "       PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
       "ID                                                       \n",
       "8959     5000.0    2000.0  112000.0    4234.0    4000.0  \n",
       "22753    1526.0    1078.0    1598.0  173026.0    6000.0  \n",
       "25883    2800.0    2400.0    2100.0    2100.0    2100.0  \n",
       "12926    3107.0    2847.0    3134.0    3072.0    3010.0  \n",
       "23599   32194.0    1729.0     590.0    9628.0   16059.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ID\n",
       "8959     1\n",
       "22753    0\n",
       "25883    0\n",
       "12926    0\n",
       "23599    0\n",
       "Name: default.payment.next.month, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_df[\"default.payment.next.month\"] = train_df[\"default.payment.next.month\"].astype(\"string\")\n",
    "# test_df[\"default.payment.next.month\"] = test_df[\"default.payment.next.month\"].astype(\"string\") \n",
    "\n",
    "X_train, y_train = train_df.drop(columns=[\"default.payment.next.month\"]), train_df[\"default.payment.next.month\"] \n",
    "X_test, y_test = test_df.drop(columns=[\"default.payment.next.month\"]), test_df[\"default.payment.next.month\"] \n",
    "display(X_train.head())\n",
    "display(y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 4. Preprocessing and transformations <a name=\"5\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 10_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Identify different feature types and the transformations you would apply on each feature type. \n",
    "2. Define a column transformer, if necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_4\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature types: \n",
    "- Numeric: `LIMIT_BAL`, `AGE`, `BILL_AMT1`, `BILL_AMT2`, `BILL_AMT3`, `BILL_AMT4`, `BILL_AMT5`, `BILL_AMT6`, `PAY_AMT1`, `PAY_AMT2`, `PAY_AMT3`, `PAY_AMT4`, `PAY_AMT5`, `PAY_AMT6`\n",
    "- Ordinal: `PAY_0`, `PAY_2`, `PAY_3`, `PAY_4`, `PAY_5`, `PAY_6`\n",
    "- Binary: `SEX`\n",
    "- Categorical: `EDUCATION`, `MARRIAGE`\n",
    "\n",
    "All non-numeric columns will need to have their data type converted with `FunctionTransformer`. Since values 0, 4, 5 and 6 for `EDUCATION` all refer to \"others\", they will be grouped together into \"4\" due to it being the most infrequent column, and since there is no clear ordinal position for \"others\", `EDUCATION` will be treated as non-ordinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical column data type to string  \n",
    "from sklearn.preprocessing import FunctionTransformer \n",
    "# https://stackoverflow.com/questions/59476179/is-it-possible-to-change-pandas-column-data-type-within-a-sklearn-pipeline\n",
    "def to_categorical(x): \n",
    "    return pd.DataFrame(x).astype(\"string\")\n",
    "fun_tr = FunctionTransformer(to_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;drop&#x27;, &#x27;drop&#x27;, []),\n",
       "                                (&#x27;standardscaler&#x27;, StandardScaler(),\n",
       "                                 [&#x27;LIMIT_BAL&#x27;, &#x27;AGE&#x27;, &#x27;BILL_AMT1&#x27;, &#x27;BILL_AMT2&#x27;,\n",
       "                                  &#x27;BILL_AMT3&#x27;, &#x27;BILL_AMT4&#x27;, &#x27;BILL_AMT5&#x27;,\n",
       "                                  &#x27;BILL_AMT6&#x27;, &#x27;PAY_AMT1&#x27;, &#x27;PAY_AMT2&#x27;,\n",
       "                                  &#x27;PAY_AMT3&#x27;, &#x27;PAY_AMT4&#x27;, &#x27;PAY_AMT5&#x27;,\n",
       "                                  &#x27;PAY_AMT6&#x27;]),\n",
       "                                (&#x27;pipeline-1&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;functiontransformer&#x27;,\n",
       "                                                  FunctionTransformer(func=&lt;function to_categorical at 0x...\n",
       "                                                                              &#x27;2&#x27;,\n",
       "                                                                              &#x27;3&#x27;,\n",
       "                                                                              &#x27;4&#x27;,\n",
       "                                                                              &#x27;5&#x27;,\n",
       "                                                                              &#x27;6&#x27;,\n",
       "                                                                              &#x27;7&#x27;,\n",
       "                                                                              &#x27;8&#x27;,\n",
       "                                                                              &#x27;9&#x27;],\n",
       "                                                                             [&#x27;-2&#x27;,\n",
       "                                                                              &#x27;-1&#x27;,\n",
       "                                                                              &#x27;0&#x27;,\n",
       "                                                                              &#x27;1&#x27;,\n",
       "                                                                              &#x27;2&#x27;,\n",
       "                                                                              &#x27;3&#x27;,\n",
       "                                                                              &#x27;4&#x27;,\n",
       "                                                                              &#x27;5&#x27;,\n",
       "                                                                              &#x27;6&#x27;,\n",
       "                                                                              &#x27;7&#x27;,\n",
       "                                                                              &#x27;8&#x27;,\n",
       "                                                                              &#x27;9&#x27;],\n",
       "                                                                             [&#x27;-2&#x27;,\n",
       "                                                                              &#x27;-1&#x27;,\n",
       "                                                                              &#x27;0&#x27;,\n",
       "                                                                              &#x27;1&#x27;,\n",
       "                                                                              &#x27;2&#x27;,\n",
       "                                                                              &#x27;3&#x27;,\n",
       "                                                                              &#x27;4&#x27;,\n",
       "                                                                              &#x27;5&#x27;,\n",
       "                                                                              &#x27;6&#x27;,\n",
       "                                                                              &#x27;7&#x27;,\n",
       "                                                                              &#x27;8&#x27;,\n",
       "                                                                              &#x27;9&#x27;],\n",
       "                                                                             [&#x27;-2&#x27;,\n",
       "                                                                              &#x27;-1&#x27;,\n",
       "                                                                              &#x27;0&#x27;,\n",
       "                                                                              &#x27;1&#x27;,\n",
       "                                                                              &#x27;2&#x27;,\n",
       "                                                                              &#x27;3&#x27;,\n",
       "                                                                              &#x27;4&#x27;,\n",
       "                                                                              &#x27;5&#x27;,\n",
       "                                                                              &#x27;6&#x27;,\n",
       "                                                                              &#x27;7&#x27;,\n",
       "                                                                              &#x27;8&#x27;,\n",
       "                                                                              &#x27;9&#x27;],\n",
       "                                                                             [&#x27;-2&#x27;,\n",
       "                                                                              &#x27;-1&#x27;,\n",
       "                                                                              &#x27;0&#x27;,\n",
       "                                                                              &#x27;1&#x27;,\n",
       "                                                                              &#x27;2&#x27;,\n",
       "                                                                              &#x27;3&#x27;,\n",
       "                                                                              &#x27;4&#x27;,\n",
       "                                                                              &#x27;5&#x27;,\n",
       "                                                                              &#x27;6&#x27;,\n",
       "                                                                              &#x27;7&#x27;,\n",
       "                                                                              &#x27;8&#x27;,\n",
       "                                                                              &#x27;9&#x27;],\n",
       "                                                                             [&#x27;-2&#x27;,\n",
       "                                                                              &#x27;-1&#x27;,\n",
       "                                                                              &#x27;0&#x27;,\n",
       "                                                                              &#x27;1&#x27;,\n",
       "                                                                              &#x27;2&#x27;,\n",
       "                                                                              &#x27;3&#x27;,\n",
       "                                                                              &#x27;4&#x27;,\n",
       "                                                                              &#x27;5&#x27;,\n",
       "                                                                              &#x27;6&#x27;,\n",
       "                                                                              &#x27;7&#x27;,\n",
       "                                                                              &#x27;8&#x27;,\n",
       "                                                                              &#x27;9&#x27;]]))]),\n",
       "                                 [&#x27;PAY_0&#x27;, &#x27;PAY_2&#x27;, &#x27;PAY_3&#x27;, &#x27;PAY_4&#x27;, &#x27;PAY_5&#x27;,\n",
       "                                  &#x27;PAY_6&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for ColumnTransformer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;drop&#x27;, &#x27;drop&#x27;, []),\n",
       "                                (&#x27;standardscaler&#x27;, StandardScaler(),\n",
       "                                 [&#x27;LIMIT_BAL&#x27;, &#x27;AGE&#x27;, &#x27;BILL_AMT1&#x27;, &#x27;BILL_AMT2&#x27;,\n",
       "                                  &#x27;BILL_AMT3&#x27;, &#x27;BILL_AMT4&#x27;, &#x27;BILL_AMT5&#x27;,\n",
       "                                  &#x27;BILL_AMT6&#x27;, &#x27;PAY_AMT1&#x27;, &#x27;PAY_AMT2&#x27;,\n",
       "                                  &#x27;PAY_AMT3&#x27;, &#x27;PAY_AMT4&#x27;, &#x27;PAY_AMT5&#x27;,\n",
       "                                  &#x27;PAY_AMT6&#x27;]),\n",
       "                                (&#x27;pipeline-1&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;functiontransformer&#x27;,\n",
       "                                                  FunctionTransformer(func=&lt;function to_categorical at 0x...\n",
       "                                                                              &#x27;2&#x27;,\n",
       "                                                                              &#x27;3&#x27;,\n",
       "                                                                              &#x27;4&#x27;,\n",
       "                                                                              &#x27;5&#x27;,\n",
       "                                                                              &#x27;6&#x27;,\n",
       "                                                                              &#x27;7&#x27;,\n",
       "                                                                              &#x27;8&#x27;,\n",
       "                                                                              &#x27;9&#x27;],\n",
       "                                                                             [&#x27;-2&#x27;,\n",
       "                                                                              &#x27;-1&#x27;,\n",
       "                                                                              &#x27;0&#x27;,\n",
       "                                                                              &#x27;1&#x27;,\n",
       "                                                                              &#x27;2&#x27;,\n",
       "                                                                              &#x27;3&#x27;,\n",
       "                                                                              &#x27;4&#x27;,\n",
       "                                                                              &#x27;5&#x27;,\n",
       "                                                                              &#x27;6&#x27;,\n",
       "                                                                              &#x27;7&#x27;,\n",
       "                                                                              &#x27;8&#x27;,\n",
       "                                                                              &#x27;9&#x27;],\n",
       "                                                                             [&#x27;-2&#x27;,\n",
       "                                                                              &#x27;-1&#x27;,\n",
       "                                                                              &#x27;0&#x27;,\n",
       "                                                                              &#x27;1&#x27;,\n",
       "                                                                              &#x27;2&#x27;,\n",
       "                                                                              &#x27;3&#x27;,\n",
       "                                                                              &#x27;4&#x27;,\n",
       "                                                                              &#x27;5&#x27;,\n",
       "                                                                              &#x27;6&#x27;,\n",
       "                                                                              &#x27;7&#x27;,\n",
       "                                                                              &#x27;8&#x27;,\n",
       "                                                                              &#x27;9&#x27;],\n",
       "                                                                             [&#x27;-2&#x27;,\n",
       "                                                                              &#x27;-1&#x27;,\n",
       "                                                                              &#x27;0&#x27;,\n",
       "                                                                              &#x27;1&#x27;,\n",
       "                                                                              &#x27;2&#x27;,\n",
       "                                                                              &#x27;3&#x27;,\n",
       "                                                                              &#x27;4&#x27;,\n",
       "                                                                              &#x27;5&#x27;,\n",
       "                                                                              &#x27;6&#x27;,\n",
       "                                                                              &#x27;7&#x27;,\n",
       "                                                                              &#x27;8&#x27;,\n",
       "                                                                              &#x27;9&#x27;],\n",
       "                                                                             [&#x27;-2&#x27;,\n",
       "                                                                              &#x27;-1&#x27;,\n",
       "                                                                              &#x27;0&#x27;,\n",
       "                                                                              &#x27;1&#x27;,\n",
       "                                                                              &#x27;2&#x27;,\n",
       "                                                                              &#x27;3&#x27;,\n",
       "                                                                              &#x27;4&#x27;,\n",
       "                                                                              &#x27;5&#x27;,\n",
       "                                                                              &#x27;6&#x27;,\n",
       "                                                                              &#x27;7&#x27;,\n",
       "                                                                              &#x27;8&#x27;,\n",
       "                                                                              &#x27;9&#x27;],\n",
       "                                                                             [&#x27;-2&#x27;,\n",
       "                                                                              &#x27;-1&#x27;,\n",
       "                                                                              &#x27;0&#x27;,\n",
       "                                                                              &#x27;1&#x27;,\n",
       "                                                                              &#x27;2&#x27;,\n",
       "                                                                              &#x27;3&#x27;,\n",
       "                                                                              &#x27;4&#x27;,\n",
       "                                                                              &#x27;5&#x27;,\n",
       "                                                                              &#x27;6&#x27;,\n",
       "                                                                              &#x27;7&#x27;,\n",
       "                                                                              &#x27;8&#x27;,\n",
       "                                                                              &#x27;9&#x27;]]))]),\n",
       "                                 [&#x27;PAY_0&#x27;, &#x27;PAY_2&#x27;, &#x27;PAY_3&#x27;, &#x27;PAY_4&#x27;, &#x27;PAY_5&#x27;,\n",
       "                                  &#x27;PAY_6&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">drop</label><div class=\"sk-toggleable__content fitted\"><pre>[]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">drop</label><div class=\"sk-toggleable__content fitted\"><pre>drop</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">standardscaler</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;LIMIT_BAL&#x27;, &#x27;AGE&#x27;, &#x27;BILL_AMT1&#x27;, &#x27;BILL_AMT2&#x27;, &#x27;BILL_AMT3&#x27;, &#x27;BILL_AMT4&#x27;, &#x27;BILL_AMT5&#x27;, &#x27;BILL_AMT6&#x27;, &#x27;PAY_AMT1&#x27;, &#x27;PAY_AMT2&#x27;, &#x27;PAY_AMT3&#x27;, &#x27;PAY_AMT4&#x27;, &#x27;PAY_AMT5&#x27;, &#x27;PAY_AMT6&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">pipeline-1</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;SEX&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function to_categorical at 0x141a40550&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(drop=&#x27;if_binary&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">pipeline-2</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;EDUCATION&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function to_categorical at 0x141a40550&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(categories=[[&#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;]],\n",
       "              handle_unknown=&#x27;infrequent_if_exist&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">pipeline-3</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;MARRIAGE&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function to_categorical at 0x141a40550&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(categories=[[&#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;]], handle_unknown=&#x27;ignore&#x27;,\n",
       "              sparse_output=False)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">pipeline-4</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;PAY_0&#x27;, &#x27;PAY_2&#x27;, &#x27;PAY_3&#x27;, &#x27;PAY_4&#x27;, &#x27;PAY_5&#x27;, &#x27;PAY_6&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function to_categorical at 0x141a40550&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OrdinalEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OrdinalEncoder.html\">?<span>Documentation for OrdinalEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OrdinalEncoder(categories=[[&#x27;-2&#x27;, &#x27;-1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;,\n",
       "                            &#x27;8&#x27;, &#x27;9&#x27;],\n",
       "                           [&#x27;-2&#x27;, &#x27;-1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;,\n",
       "                            &#x27;8&#x27;, &#x27;9&#x27;],\n",
       "                           [&#x27;-2&#x27;, &#x27;-1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;,\n",
       "                            &#x27;8&#x27;, &#x27;9&#x27;],\n",
       "                           [&#x27;-2&#x27;, &#x27;-1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;,\n",
       "                            &#x27;8&#x27;, &#x27;9&#x27;],\n",
       "                           [&#x27;-2&#x27;, &#x27;-1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;,\n",
       "                            &#x27;8&#x27;, &#x27;9&#x27;],\n",
       "                           [&#x27;-2&#x27;, &#x27;-1&#x27;, &#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;,\n",
       "                            &#x27;8&#x27;, &#x27;9&#x27;]])</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('drop', 'drop', []),\n",
       "                                ('standardscaler', StandardScaler(),\n",
       "                                 ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'BILL_AMT2',\n",
       "                                  'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5',\n",
       "                                  'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2',\n",
       "                                  'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5',\n",
       "                                  'PAY_AMT6']),\n",
       "                                ('pipeline-1',\n",
       "                                 Pipeline(steps=[('functiontransformer',\n",
       "                                                  FunctionTransformer(func=<function to_categorical at 0x...\n",
       "                                                                              '2',\n",
       "                                                                              '3',\n",
       "                                                                              '4',\n",
       "                                                                              '5',\n",
       "                                                                              '6',\n",
       "                                                                              '7',\n",
       "                                                                              '8',\n",
       "                                                                              '9'],\n",
       "                                                                             ['-2',\n",
       "                                                                              '-1',\n",
       "                                                                              '0',\n",
       "                                                                              '1',\n",
       "                                                                              '2',\n",
       "                                                                              '3',\n",
       "                                                                              '4',\n",
       "                                                                              '5',\n",
       "                                                                              '6',\n",
       "                                                                              '7',\n",
       "                                                                              '8',\n",
       "                                                                              '9'],\n",
       "                                                                             ['-2',\n",
       "                                                                              '-1',\n",
       "                                                                              '0',\n",
       "                                                                              '1',\n",
       "                                                                              '2',\n",
       "                                                                              '3',\n",
       "                                                                              '4',\n",
       "                                                                              '5',\n",
       "                                                                              '6',\n",
       "                                                                              '7',\n",
       "                                                                              '8',\n",
       "                                                                              '9'],\n",
       "                                                                             ['-2',\n",
       "                                                                              '-1',\n",
       "                                                                              '0',\n",
       "                                                                              '1',\n",
       "                                                                              '2',\n",
       "                                                                              '3',\n",
       "                                                                              '4',\n",
       "                                                                              '5',\n",
       "                                                                              '6',\n",
       "                                                                              '7',\n",
       "                                                                              '8',\n",
       "                                                                              '9'],\n",
       "                                                                             ['-2',\n",
       "                                                                              '-1',\n",
       "                                                                              '0',\n",
       "                                                                              '1',\n",
       "                                                                              '2',\n",
       "                                                                              '3',\n",
       "                                                                              '4',\n",
       "                                                                              '5',\n",
       "                                                                              '6',\n",
       "                                                                              '7',\n",
       "                                                                              '8',\n",
       "                                                                              '9'],\n",
       "                                                                             ['-2',\n",
       "                                                                              '-1',\n",
       "                                                                              '0',\n",
       "                                                                              '1',\n",
       "                                                                              '2',\n",
       "                                                                              '3',\n",
       "                                                                              '4',\n",
       "                                                                              '5',\n",
       "                                                                              '6',\n",
       "                                                                              '7',\n",
       "                                                                              '8',\n",
       "                                                                              '9']]))]),\n",
       "                                 ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',\n",
       "                                  'PAY_6'])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adapted from Lecture 10\n",
    "\n",
    "numeric_features = [\"LIMIT_BAL\", \"AGE\", \"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\", \"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\",]\n",
    "# numeric_features = [\"LIMIT_BAL\", \"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\", \"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\",]\n",
    "\n",
    "ordinal_features_reg = [\"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\",]\n",
    "# ordinal_features_oth = [\"EDUCATION\",]\n",
    "\n",
    "binary_features = [\"SEX\",] \n",
    "categorical_features_E = [\"EDUCATION\",]\n",
    "categorical_features_M = [\"MARRIAGE\",]\n",
    "# categorical_features = [\"EDUCATION\", \"MARRIAGE\",]\n",
    "\n",
    "# drop_features = [\"SEX\", \"MARRIAGE\", \"AGE\",] # MAYBE, NEED TO DISCUSS\n",
    "# drop_features = [\"SEX\", \"EDUCATION\", \"MARRIAGE\",] # MAYBE, NEED TO DISCUSS\n",
    "drop_features = []\n",
    "\n",
    "# Ordering for ordinal features with same order \n",
    "# ordering = [\"9\", \"8\", \"7\", \"6\", \"5\", \"4\", \"3\", \"2\", \"1\", \"0\", \"-1\", \"-2\",] \n",
    "ordering = [\"-2\", \"-1\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\",] \n",
    "ordering_ordinal_reg = [ordering] * len(ordinal_features_reg)\n",
    "# print(ordering_ordinal_reg)\n",
    "# Ordering for ordinal features with different order \n",
    "# ordering_ordinal_oth = [[],]\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "ordinal_transformer_reg = make_pipeline(fun_tr, OrdinalEncoder(categories=ordering_ordinal_reg)) \n",
    "# ordinal_transformer_oth = make_pipeline(fun_tr, OrdinalEncoder(categories=ordering_ordinal_oth))\n",
    "binary_transformer = make_pipeline(fun_tr, OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop = \"if_binary\"),)\n",
    "# categorical_transformer = make_pipeline(fun_tr, OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),)\n",
    "categorical_transformer_E = make_pipeline(fun_tr, OneHotEncoder(categories = [[\"1\", \"2\", \"3\", \"4\"]], handle_unknown=\"infrequent_if_exist\", sparse_output=False),)\n",
    "categorical_transformer_M = make_pipeline(fun_tr, OneHotEncoder(categories = [[\"0\", \"1\", \"2\", \"3\"]], handle_unknown=\"ignore\", sparse_output=False),)\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (\"drop\", drop_features),\n",
    "    (numeric_transformer, numeric_features),\n",
    "    # (ordinal_transformer_oth, ordinal_features_oth),\n",
    "    (binary_transformer, binary_features),\n",
    "    # (categorical_transformer, categorical_features),\n",
    "    (categorical_transformer_E, categorical_features_E),\n",
    "    (categorical_transformer_M, categorical_features_M),\n",
    "    (ordinal_transformer_reg, ordinal_features_reg),\n",
    ")\n",
    "preprocessor.fit(X_train)\n",
    "display(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>...</th>\n",
       "      <th>MARRIAGE_0</th>\n",
       "      <th>MARRIAGE_1</th>\n",
       "      <th>MARRIAGE_2</th>\n",
       "      <th>MARRIAGE_3</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8959</th>\n",
       "      <td>1.327292</td>\n",
       "      <td>0.939905</td>\n",
       "      <td>0.433921</td>\n",
       "      <td>0.516430</td>\n",
       "      <td>0.390631</td>\n",
       "      <td>0.255174</td>\n",
       "      <td>1.920088</td>\n",
       "      <td>1.212636</td>\n",
       "      <td>0.886674</td>\n",
       "      <td>-0.044007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22753</th>\n",
       "      <td>0.249673</td>\n",
       "      <td>-0.154656</td>\n",
       "      <td>2.094514</td>\n",
       "      <td>1.813839</td>\n",
       "      <td>-0.625196</td>\n",
       "      <td>-0.657545</td>\n",
       "      <td>-0.637820</td>\n",
       "      <td>2.253487</td>\n",
       "      <td>-0.005990</td>\n",
       "      <td>-0.188312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25883</th>\n",
       "      <td>-0.674001</td>\n",
       "      <td>-1.030305</td>\n",
       "      <td>0.377072</td>\n",
       "      <td>0.441322</td>\n",
       "      <td>0.396381</td>\n",
       "      <td>0.507760</td>\n",
       "      <td>0.291611</td>\n",
       "      <td>0.330471</td>\n",
       "      <td>-0.172502</td>\n",
       "      <td>-0.135392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12926</th>\n",
       "      <td>-0.674001</td>\n",
       "      <td>1.049361</td>\n",
       "      <td>0.386305</td>\n",
       "      <td>0.456687</td>\n",
       "      <td>0.491731</td>\n",
       "      <td>0.568122</td>\n",
       "      <td>0.679148</td>\n",
       "      <td>0.712040</td>\n",
       "      <td>-0.152181</td>\n",
       "      <td>-0.122640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23599</th>\n",
       "      <td>-0.674001</td>\n",
       "      <td>0.502080</td>\n",
       "      <td>-0.657617</td>\n",
       "      <td>-0.660957</td>\n",
       "      <td>-0.211069</td>\n",
       "      <td>-0.647344</td>\n",
       "      <td>-0.654508</td>\n",
       "      <td>-0.491003</td>\n",
       "      <td>-0.219611</td>\n",
       "      <td>1.085587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL       AGE  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  \\\n",
       "ID                                                                       \n",
       "8959    1.327292  0.939905   0.433921   0.516430   0.390631   0.255174   \n",
       "22753   0.249673 -0.154656   2.094514   1.813839  -0.625196  -0.657545   \n",
       "25883  -0.674001 -1.030305   0.377072   0.441322   0.396381   0.507760   \n",
       "12926  -0.674001  1.049361   0.386305   0.456687   0.491731   0.568122   \n",
       "23599  -0.674001  0.502080  -0.657617  -0.660957  -0.211069  -0.647344   \n",
       "\n",
       "       BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  ...  MARRIAGE_0  MARRIAGE_1  \\\n",
       "ID                                               ...                           \n",
       "8959    1.920088   1.212636  0.886674 -0.044007  ...         0.0         0.0   \n",
       "22753  -0.637820   2.253487 -0.005990 -0.188312  ...         0.0         0.0   \n",
       "25883   0.291611   0.330471 -0.172502 -0.135392  ...         0.0         1.0   \n",
       "12926   0.679148   0.712040 -0.152181 -0.122640  ...         0.0         1.0   \n",
       "23599  -0.654508  -0.491003 -0.219611  1.085587  ...         0.0         1.0   \n",
       "\n",
       "       MARRIAGE_2  MARRIAGE_3  PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  PAY_6  \n",
       "ID                                                                       \n",
       "8959          1.0         0.0    2.0    2.0    2.0    2.0    2.0    2.0  \n",
       "22753         1.0         0.0    2.0    2.0    2.0    1.0    1.0    1.0  \n",
       "25883         0.0         0.0    2.0    2.0    2.0    2.0    2.0    2.0  \n",
       "12926         0.0         0.0    2.0    2.0    2.0    2.0    2.0    2.0  \n",
       "23599         0.0         0.0    1.0    1.0    1.0    1.0    1.0    1.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binary_features_cols = preprocessor.named_transformers_[\"pipeline-3\"].named_steps[\"onehotencoder\"].get_feature_names_out(binary_features)\n",
    "categorical_features_E_cols = list(preprocessor.named_transformers_[\"pipeline-2\"].named_steps[\"onehotencoder\"].get_feature_names_out(categorical_features_E))\n",
    "categorical_features_M_cols = list(preprocessor.named_transformers_[\"pipeline-3\"].named_steps[\"onehotencoder\"].get_feature_names_out(categorical_features_M))\n",
    "new_columns = (\n",
    "    numeric_features + binary_features + categorical_features_E_cols + categorical_features_M_cols + ordinal_features_reg\n",
    ")\n",
    "X_train_enc = pd.DataFrame(\n",
    "    preprocessor.transform(X_train), index=X_train.index, columns=new_columns\n",
    ")\n",
    "X_train_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 5. Baseline model <a name=\"6\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 2_\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try `scikit-learn`'s baseline model and report results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_5\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the baseline model predicts every value as 0, the `test_accuracy` value obtained from `mean_std_cross_val_scores()` is identical to the proportion of 0 obtained in the EDA. Due to `DummyClassifier()` making predictions that ignore the input features, it does not have any precision, recall or F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained from Lecture 3 \n",
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_66134/3217439548.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.172 (+/- 0.123)</td>\n",
       "      <td>0.060 (+/- 0.056)</td>\n",
       "      <td>0.778 (+/- 0.000)</td>\n",
       "      <td>0.778 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fit_time         score_time      test_accuracy  \\\n",
       "Dummy  0.172 (+/- 0.123)  0.060 (+/- 0.056)  0.778 (+/- 0.000)   \n",
       "\n",
       "          train_accuracy     test_precision    train_precision  \\\n",
       "Dummy  0.778 (+/- 0.000)  0.000 (+/- 0.000)  0.000 (+/- 0.000)   \n",
       "\n",
       "             test_recall       train_recall            test_f1  \\\n",
       "Dummy  0.000 (+/- 0.000)  0.000 (+/- 0.000)  0.000 (+/- 0.000)   \n",
       "\n",
       "                train_f1  \n",
       "Dummy  0.000 (+/- 0.000)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adapted from Lecture 9 \n",
    "results = {}\n",
    "scoring_metric = [\"accuracy\",\"precision\",\"recall\",\"f1\",]  # scoring can be a string, a list, or a dictionary\n",
    "dummy = make_pipeline(preprocessor, DummyClassifier(random_state = 76))\n",
    "print()\n",
    "results[\"Dummy\"] = mean_std_cross_val_scores(\n",
    "    dummy, X_train, y_train, cv = 10, \n",
    "    return_train_score = True, scoring = scoring_metric\n",
    ")\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 6. Linear models <a name=\"7\"></a>\n",
    "<hr>\n",
    "\n",
    "_points 10_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try a linear model as a first real attempt. \n",
    "2. Carry out hyperparameter tuning to explore different values for the complexity hyperparameter. \n",
    "3. Report cross-validation scores along with standard deviation. \n",
    "4. Summarize your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_6\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4)\n",
    "\n",
    "We first tried the logistic regression model. Our hyperparameters of interest are `C` and `class_weight`, with the aim to optimise the F1-score. Through `RandomizedSearchCV`, the optimal `class_weight` was 1:5, while the optimal `C` value remained at 1. We saw significant improvement from 0.357 (+/- 0.033) to 0.414 (+/- 0.008) in our `test_f1`, but the fix time and score time were slightly increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/student/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_lr: {'logisticregression__class_weight': {0: 1, 1: 5}, 'logisticregression__C': 1}\n",
      "best_score_lr: 0.41334547931430404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_66134/3217439548.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_66134/3217439548.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.172 (+/- 0.123)</td>\n",
       "      <td>0.060 (+/- 0.056)</td>\n",
       "      <td>0.778 (+/- 0.000)</td>\n",
       "      <td>0.778 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.190 (+/- 0.016)</td>\n",
       "      <td>0.019 (+/- 0.001)</td>\n",
       "      <td>0.810 (+/- 0.007)</td>\n",
       "      <td>0.811 (+/- 0.001)</td>\n",
       "      <td>0.714 (+/- 0.042)</td>\n",
       "      <td>0.719 (+/- 0.005)</td>\n",
       "      <td>0.238 (+/- 0.025)</td>\n",
       "      <td>0.240 (+/- 0.004)</td>\n",
       "      <td>0.357 (+/- 0.033)</td>\n",
       "      <td>0.359 (+/- 0.005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (Optimised)</th>\n",
       "      <td>0.218 (+/- 0.025)</td>\n",
       "      <td>0.020 (+/- 0.001)</td>\n",
       "      <td>0.509 (+/- 0.011)</td>\n",
       "      <td>0.510 (+/- 0.002)</td>\n",
       "      <td>0.281 (+/- 0.006)</td>\n",
       "      <td>0.282 (+/- 0.001)</td>\n",
       "      <td>0.780 (+/- 0.013)</td>\n",
       "      <td>0.784 (+/- 0.002)</td>\n",
       "      <td>0.414 (+/- 0.007)</td>\n",
       "      <td>0.415 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          fit_time         score_time  \\\n",
       "Dummy                            0.172 (+/- 0.123)  0.060 (+/- 0.056)   \n",
       "Logistic Regression              0.190 (+/- 0.016)  0.019 (+/- 0.001)   \n",
       "Logistic Regression (Optimised)  0.218 (+/- 0.025)  0.020 (+/- 0.001)   \n",
       "\n",
       "                                     test_accuracy     train_accuracy  \\\n",
       "Dummy                            0.778 (+/- 0.000)  0.778 (+/- 0.000)   \n",
       "Logistic Regression              0.810 (+/- 0.007)  0.811 (+/- 0.001)   \n",
       "Logistic Regression (Optimised)  0.509 (+/- 0.011)  0.510 (+/- 0.002)   \n",
       "\n",
       "                                    test_precision    train_precision  \\\n",
       "Dummy                            0.000 (+/- 0.000)  0.000 (+/- 0.000)   \n",
       "Logistic Regression              0.714 (+/- 0.042)  0.719 (+/- 0.005)   \n",
       "Logistic Regression (Optimised)  0.281 (+/- 0.006)  0.282 (+/- 0.001)   \n",
       "\n",
       "                                       test_recall       train_recall  \\\n",
       "Dummy                            0.000 (+/- 0.000)  0.000 (+/- 0.000)   \n",
       "Logistic Regression              0.238 (+/- 0.025)  0.240 (+/- 0.004)   \n",
       "Logistic Regression (Optimised)  0.780 (+/- 0.013)  0.784 (+/- 0.002)   \n",
       "\n",
       "                                           test_f1           train_f1  \n",
       "Dummy                            0.000 (+/- 0.000)  0.000 (+/- 0.000)  \n",
       "Logistic Regression              0.357 (+/- 0.033)  0.359 (+/- 0.005)  \n",
       "Logistic Regression (Optimised)  0.414 (+/- 0.007)  0.415 (+/- 0.001)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adapted from HW4 and Lecture 8 \n",
    "# (2) \n",
    "# https://levelup.gitconnected.com/a-comprehensive-analysis-of-hyperparameter-optimization-in-logistic-regression-models-521564c1bfc0\n",
    "pipe_lr = make_pipeline(preprocessor, LogisticRegression(random_state = 76, max_iter = 200))\n",
    "# pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "param_grid_lr = {\n",
    "    \"logisticregression__C\": [0.01, 0.1, 1, 10, 100], \n",
    "    \"logisticregression__class_weight\": [{0: 1, 1: x} for x in [0.5, 1, 3, 5, 7]]\n",
    "}\n",
    "random_search_lr = RandomizedSearchCV(\n",
    "    pipe_lr, param_distributions = param_grid_lr, n_iter=10,\n",
    "    n_jobs = -1, return_train_score = True, random_state = 76,scoring='f1'\n",
    ")  \n",
    "random_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# pd.DataFrame(random_search.cv_results_)[relevant].set_index(\"rank_test_score\").sort_index().T\n",
    "\n",
    "best_params_lr = random_search_lr.best_params_\n",
    "best_score_lr = random_search_lr.best_score_\n",
    "\n",
    "print(\"best_params_lr: \" + str(best_params_lr))\n",
    "print(\"best_score_lr: \" + str(best_score_lr))\n",
    "\n",
    "# (3)\n",
    "pipe_lr_opt = make_pipeline(\n",
    "    preprocessor, \n",
    "    LogisticRegression(\n",
    "        random_state = 76, \n",
    "        max_iter = 200, \n",
    "        C = best_params_lr[\"logisticregression__C\"],\n",
    "        class_weight = best_params_lr[\"logisticregression__class_weight\"],\n",
    "    ))\n",
    "pipe_lr_opt.fit(X_train, y_train)\n",
    "\n",
    "results[\"Logistic Regression\"] = mean_std_cross_val_scores(pipe_lr, X_train, y_train, cv = 10, return_train_score = True, scoring = scoring_metric)\n",
    "results[\"Logistic Regression (Optimised)\"] = mean_std_cross_val_scores(pipe_lr_opt, X_train, y_train, cv = 10, return_train_score = True, scoring = scoring_metric)\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 7. Different models <a name=\"8\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 12_\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try at least 3 other models aside from a linear model. One of these models should be a tree-based ensemble model. \n",
    "2. Summarize your results in terms of overfitting/underfitting and fit and score times. Can you beat a linear model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_7\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) \n",
    "\n",
    "The non-optimised `DecisionTreeClassifier()` and `RandomForestClassifier()` are likely overfitted, as their `train_f1` scores of 0.999 (+/- 0.000) are unrealistically high compared to their `test_f1` scores of 0.400 (+/- 0.024) and 0.477 (+/- 0.026) respectively. The non-optimised `HistGradientBoostingClassifier()` provides higher values for `train_f1` and `test_f1` compared to the linear model, increasing the value of `test_f1` from 0.414 (+/- 0.007) to 0.477 (+/- 0.023), while the increase in `score_time` from 0.028 (+/- 0.016) to 0.032 (+/- 0.002) is not great enough to be significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_66134/3217439548.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_66134/3217439548.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_66134/3217439548.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.172 (+/- 0.123)</td>\n",
       "      <td>0.060 (+/- 0.056)</td>\n",
       "      <td>0.778 (+/- 0.000)</td>\n",
       "      <td>0.778 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.190 (+/- 0.016)</td>\n",
       "      <td>0.019 (+/- 0.001)</td>\n",
       "      <td>0.810 (+/- 0.007)</td>\n",
       "      <td>0.811 (+/- 0.001)</td>\n",
       "      <td>0.714 (+/- 0.042)</td>\n",
       "      <td>0.719 (+/- 0.005)</td>\n",
       "      <td>0.238 (+/- 0.025)</td>\n",
       "      <td>0.240 (+/- 0.004)</td>\n",
       "      <td>0.357 (+/- 0.033)</td>\n",
       "      <td>0.359 (+/- 0.005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (Optimised)</th>\n",
       "      <td>0.218 (+/- 0.025)</td>\n",
       "      <td>0.020 (+/- 0.001)</td>\n",
       "      <td>0.509 (+/- 0.011)</td>\n",
       "      <td>0.510 (+/- 0.002)</td>\n",
       "      <td>0.281 (+/- 0.006)</td>\n",
       "      <td>0.282 (+/- 0.001)</td>\n",
       "      <td>0.780 (+/- 0.013)</td>\n",
       "      <td>0.784 (+/- 0.002)</td>\n",
       "      <td>0.414 (+/- 0.007)</td>\n",
       "      <td>0.415 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.724 (+/- 0.178)</td>\n",
       "      <td>0.025 (+/- 0.011)</td>\n",
       "      <td>0.723 (+/- 0.010)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "      <td>0.385 (+/- 0.020)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "      <td>0.417 (+/- 0.030)</td>\n",
       "      <td>0.998 (+/- 0.000)</td>\n",
       "      <td>0.400 (+/- 0.024)</td>\n",
       "      <td>0.999 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>2.469 (+/- 1.537)</td>\n",
       "      <td>0.155 (+/- 0.287)</td>\n",
       "      <td>0.817 (+/- 0.008)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "      <td>0.653 (+/- 0.031)</td>\n",
       "      <td>0.999 (+/- 0.000)</td>\n",
       "      <td>0.376 (+/- 0.024)</td>\n",
       "      <td>0.999 (+/- 0.000)</td>\n",
       "      <td>0.477 (+/- 0.026)</td>\n",
       "      <td>0.999 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn_histGB</th>\n",
       "      <td>1.607 (+/- 0.471)</td>\n",
       "      <td>0.062 (+/- 0.069)</td>\n",
       "      <td>0.820 (+/- 0.007)</td>\n",
       "      <td>0.834 (+/- 0.004)</td>\n",
       "      <td>0.673 (+/- 0.027)</td>\n",
       "      <td>0.726 (+/- 0.017)</td>\n",
       "      <td>0.370 (+/- 0.022)</td>\n",
       "      <td>0.403 (+/- 0.010)</td>\n",
       "      <td>0.477 (+/- 0.023)</td>\n",
       "      <td>0.518 (+/- 0.012)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          fit_time         score_time  \\\n",
       "Dummy                            0.172 (+/- 0.123)  0.060 (+/- 0.056)   \n",
       "Logistic Regression              0.190 (+/- 0.016)  0.019 (+/- 0.001)   \n",
       "Logistic Regression (Optimised)  0.218 (+/- 0.025)  0.020 (+/- 0.001)   \n",
       "Decision tree                    0.724 (+/- 0.178)  0.025 (+/- 0.011)   \n",
       "Random forest                    2.469 (+/- 1.537)  0.155 (+/- 0.287)   \n",
       "sklearn_histGB                   1.607 (+/- 0.471)  0.062 (+/- 0.069)   \n",
       "\n",
       "                                     test_accuracy     train_accuracy  \\\n",
       "Dummy                            0.778 (+/- 0.000)  0.778 (+/- 0.000)   \n",
       "Logistic Regression              0.810 (+/- 0.007)  0.811 (+/- 0.001)   \n",
       "Logistic Regression (Optimised)  0.509 (+/- 0.011)  0.510 (+/- 0.002)   \n",
       "Decision tree                    0.723 (+/- 0.010)  1.000 (+/- 0.000)   \n",
       "Random forest                    0.817 (+/- 0.008)  1.000 (+/- 0.000)   \n",
       "sklearn_histGB                   0.820 (+/- 0.007)  0.834 (+/- 0.004)   \n",
       "\n",
       "                                    test_precision    train_precision  \\\n",
       "Dummy                            0.000 (+/- 0.000)  0.000 (+/- 0.000)   \n",
       "Logistic Regression              0.714 (+/- 0.042)  0.719 (+/- 0.005)   \n",
       "Logistic Regression (Optimised)  0.281 (+/- 0.006)  0.282 (+/- 0.001)   \n",
       "Decision tree                    0.385 (+/- 0.020)  1.000 (+/- 0.000)   \n",
       "Random forest                    0.653 (+/- 0.031)  0.999 (+/- 0.000)   \n",
       "sklearn_histGB                   0.673 (+/- 0.027)  0.726 (+/- 0.017)   \n",
       "\n",
       "                                       test_recall       train_recall  \\\n",
       "Dummy                            0.000 (+/- 0.000)  0.000 (+/- 0.000)   \n",
       "Logistic Regression              0.238 (+/- 0.025)  0.240 (+/- 0.004)   \n",
       "Logistic Regression (Optimised)  0.780 (+/- 0.013)  0.784 (+/- 0.002)   \n",
       "Decision tree                    0.417 (+/- 0.030)  0.998 (+/- 0.000)   \n",
       "Random forest                    0.376 (+/- 0.024)  0.999 (+/- 0.000)   \n",
       "sklearn_histGB                   0.370 (+/- 0.022)  0.403 (+/- 0.010)   \n",
       "\n",
       "                                           test_f1           train_f1  \n",
       "Dummy                            0.000 (+/- 0.000)  0.000 (+/- 0.000)  \n",
       "Logistic Regression              0.357 (+/- 0.033)  0.359 (+/- 0.005)  \n",
       "Logistic Regression (Optimised)  0.414 (+/- 0.007)  0.415 (+/- 0.001)  \n",
       "Decision tree                    0.400 (+/- 0.024)  0.999 (+/- 0.000)  \n",
       "Random forest                    0.477 (+/- 0.026)  0.999 (+/- 0.000)  \n",
       "sklearn_histGB                   0.477 (+/- 0.023)  0.518 (+/- 0.012)  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adapted from Lecture 11\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# Decision tree \n",
    "# Hyperparameters: max_depth \n",
    "# https://ken-hoffman.medium.com/decision-tree-hyperparameters-explained-49158ee1268e\n",
    "pipe_dt = make_pipeline(preprocessor, DecisionTreeClassifier(random_state=76))\n",
    "# pipe_dt.fit(X_train, y_train)\n",
    "results[\"Decision tree\"] = mean_std_cross_val_scores(\n",
    "    pipe_dt, X_train, y_train, cv = 10, return_train_score = True, scoring=scoring_metric\n",
    ")\n",
    "\n",
    "# Random forest \n",
    "# Hyperparameters: n_estimators, max_depth, max_features\n",
    "pipe_rf = make_pipeline(\n",
    "    preprocessor, RandomForestClassifier(n_jobs=-1, random_state=76,)\n",
    ")\n",
    "# pipe_rf.fit(X_train, y_train)\n",
    "results[\"Random forest\"] = mean_std_cross_val_scores(\n",
    "    pipe_rf, X_train, y_train, cv = 10, return_train_score = True, scoring=scoring_metric\n",
    ")\n",
    "\n",
    "# Tree-based ensemble model (HistGradientBoostingClassifier due to large dataset size) \n",
    "# Hyperparameters: learning_rate, max_depth \n",
    "pipe_sklearn_histGB = make_pipeline(\n",
    "    preprocessor,\n",
    "    HistGradientBoostingClassifier(random_state=76),\n",
    ")\n",
    "# pipe_sklearn_histGB.fit(X_train, y_train)\n",
    "results[\"sklearn_histGB\"] = mean_std_cross_val_scores(\n",
    "    pipe_sklearn_histGB, X_train, y_train, cv = 10, return_train_score = True, scoring=scoring_metric\n",
    ")\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 8. Hyperparameter optimization <a name=\"10\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 10_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. In at least one case you should be optimizing multiple hyperparameters for a single model. You may use `sklearn`'s methods for hyperparameter optimization or fancier Bayesian optimization methods. \n",
    "  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n",
    "  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_8\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the size of the dataset and the number of hyperparameters to be adjusted for each case, along with some parameters being more directly important to the prediction of `default.payment.next.month`, such as `LIMIT_BAL` compared to `AGE`, `RandomizedSearchCV()` has been applied to each of the models. \n",
    "\n",
    "Due to the class imbalance within `default.payment.next.month`, the `class_weight` parameter is treated as a hyperparameter for each model. \n",
    "\n",
    "The optimised `DecisionTreeClassifier()`, `RandomForestClassifier()` and `HistGradientBoostingClassifier()` models provide better `test_f1` scores than the optimised linear model, and notably perform better than the stacking ensemble model composed of all the optimised models. Given the results, the optimised  provides the greatest combination of `test_f1` and `train_f1` scores of 0.538 (+/- 0.012) and 0.587 (+/- 0.006) respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_dt: {'decisiontreeclassifier__max_depth': 5, 'decisiontreeclassifier__class_weight': {0: 1, 1: 3}}\n",
      "best_score_dt: 0.5276478299069992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_66134/3217439548.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n"
     ]
    }
   ],
   "source": [
    "# Adapted from Lecture 8 and 11\n",
    "\n",
    "# Decision tree \n",
    "# Hyperparameters: max_depth \n",
    "# https://ken-hoffman.medium.com/decision-tree-hyperparameters-explained-49158ee1268e\n",
    "param_grid_dt = {\n",
    "    \"decisiontreeclassifier__max_depth\": np.arange(1, 20, 4), \n",
    "    \"decisiontreeclassifier__class_weight\": [{0: 1, 1: x} for x in [0.5, 1, 3, 5, 7]]\n",
    "}\n",
    "random_search_dt = RandomizedSearchCV(\n",
    "    pipe_dt, param_distributions = param_grid_dt, n_iter=10,\n",
    "    n_jobs = -1, return_train_score = True, random_state = 76, scoring='f1'\n",
    ")  \n",
    "random_search_dt.fit(X_train, y_train)\n",
    "\n",
    "best_params_dt = random_search_dt.best_params_\n",
    "best_score_dt = random_search_dt.best_score_\n",
    "print(\"best_params_dt: \" + str(best_params_dt))\n",
    "print(\"best_score_dt: \" + str(best_score_dt))\n",
    "\n",
    "pipe_dt_opt = make_pipeline(\n",
    "    preprocessor, \n",
    "    DecisionTreeClassifier(\n",
    "        max_depth = best_params_dt[\"decisiontreeclassifier__max_depth\"], \n",
    "        class_weight = best_params_dt[\"decisiontreeclassifier__class_weight\"],\n",
    "        random_state=76\n",
    "    )\n",
    ")\n",
    "results[\"Decision tree (Optimised)\"] = mean_std_cross_val_scores(\n",
    "    pipe_dt_opt, X_train, y_train, cv = 10, return_train_score = True, scoring=scoring_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_rf: {'randomforestclassifier__n_estimators': 400, 'randomforestclassifier__max_features': 20, 'randomforestclassifier__max_depth': 5, 'randomforestclassifier__class_weight': {0: 1, 1: 3}}\n",
      "best_score_rf: 0.5378310135957054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_66134/3217439548.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n"
     ]
    }
   ],
   "source": [
    "# Random forest \n",
    "# Hyperparameters: n_estimators, max_depth, max_features, class_weight\n",
    "param_grid_rf = {\n",
    "    \"randomforestclassifier__max_depth\": np.arange(1, 20, 4), \n",
    "    \"randomforestclassifier__n_estimators\": [100, 200, 300, 400, 500], \n",
    "    \"randomforestclassifier__max_features\": [5, 10, 15, 20, 25, 30], \n",
    "    \"randomforestclassifier__class_weight\": [{0: 1, 1: x} for x in [0.5, 1, 3, 5, 7]],\n",
    "}\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    pipe_rf, param_distributions = param_grid_rf, n_iter=10,\n",
    "    n_jobs = -1, return_train_score = True, random_state = 76, scoring='f1'\n",
    ")  \n",
    "random_search_rf.fit(X_train, y_train)\n",
    "\n",
    "best_params_rf = random_search_rf.best_params_\n",
    "best_score_rf = random_search_rf.best_score_\n",
    "print(\"best_params_rf: \" + str(best_params_rf))\n",
    "print(\"best_score_rf: \" + str(best_score_rf))\n",
    "\n",
    "pipe_rf_opt = make_pipeline(\n",
    "    preprocessor, \n",
    "    RandomForestClassifier(\n",
    "        n_estimators = best_params_rf[\"randomforestclassifier__n_estimators\"], \n",
    "        max_depth = best_params_rf[\"randomforestclassifier__max_depth\"], \n",
    "        max_features = best_params_rf[\"randomforestclassifier__max_features\"], \n",
    "        class_weight = best_params_rf[\"randomforestclassifier__class_weight\"],\n",
    "        n_jobs=-1, random_state=76,\n",
    "    )\n",
    ")\n",
    "results[\"Random forest (Optimised)\"] = mean_std_cross_val_scores(\n",
    "    pipe_rf_opt, X_train, y_train, cv = 10, return_train_score = True, scoring=scoring_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_sklearn_histGB: {'histgradientboostingclassifier__max_depth': 13, 'histgradientboostingclassifier__learning_rate': 0.1, 'histgradientboostingclassifier__class_weight': {0: 1, 1: 3}}\n",
      "best_score_sklearn_histGB: 0.539481244308669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_66134/3217439548.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n"
     ]
    }
   ],
   "source": [
    "# Tree-based ensemble model (HistGradientBoostingClassifier due to large dataset size) \n",
    "# Hyperparameters: learning_rate, max_depth \n",
    "param_grid_sklearn_histGB = {\n",
    "    \"histgradientboostingclassifier__max_depth\": np.arange(1, 20, 4), \n",
    "    \"histgradientboostingclassifier__learning_rate\": [0.1, 0.3, 0.5, 0.7, 0.9,],  \n",
    "    \"histgradientboostingclassifier__class_weight\": [{0: 1, 1: x} for x in [0.5, 1, 3, 5, 7]]\n",
    "}\n",
    "random_search_sklearn_histGB = RandomizedSearchCV(\n",
    "    pipe_sklearn_histGB, param_distributions = param_grid_sklearn_histGB, n_iter=10,\n",
    "    n_jobs = -1, return_train_score = True, random_state = 76,scoring='f1'\n",
    ")  \n",
    "random_search_sklearn_histGB.fit(X_train, y_train)\n",
    "\n",
    "best_params_sklearn_histGB = random_search_sklearn_histGB.best_params_\n",
    "best_score_sklearn_histGB = random_search_sklearn_histGB.best_score_\n",
    "\n",
    "print(\"best_params_sklearn_histGB: \" + str(best_params_sklearn_histGB))\n",
    "print(\"best_score_sklearn_histGB: \" + str(best_score_sklearn_histGB))\n",
    "\n",
    "pipe_sklearn_histGB_opt = make_pipeline(\n",
    "    preprocessor,\n",
    "    HistGradientBoostingClassifier(\n",
    "        learning_rate = best_params_sklearn_histGB[\"histgradientboostingclassifier__learning_rate\"], \n",
    "        max_depth = best_params_sklearn_histGB[\"histgradientboostingclassifier__max_depth\"],\n",
    "        class_weight = best_params_sklearn_histGB[\"histgradientboostingclassifier__class_weight\"],\n",
    "        random_state=76\n",
    "    ),\n",
    ")\n",
    "results[\"sklearn_histGB (Optimised)\"] = mean_std_cross_val_scores(\n",
    "    pipe_sklearn_histGB_opt, X_train, y_train, cv = 10, return_train_score = True, scoring=scoring_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MARRIAGE_0</th>\n",
       "      <td>-1.438142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <td>-0.258907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <td>-0.170688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARRIAGE_2</th>\n",
       "      <td>-0.170011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <td>-0.140386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION_4</th>\n",
       "      <td>-0.108805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <td>-0.100438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEX</th>\n",
       "      <td>-0.088415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <td>-0.063235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARRIAGE_3</th>\n",
       "      <td>-0.061553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <td>-0.049132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <td>-0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <td>-0.033158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <td>-0.028955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARRIAGE_1</th>\n",
       "      <td>-0.027349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_6</th>\n",
       "      <td>-0.010290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_4</th>\n",
       "      <td>-0.008917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_5</th>\n",
       "      <td>0.029433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_3</th>\n",
       "      <td>0.047937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <td>0.057784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <td>0.062594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <td>0.067688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.070023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_2</th>\n",
       "      <td>0.100413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_0</th>\n",
       "      <td>0.496889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION_3</th>\n",
       "      <td>0.912959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION_2</th>\n",
       "      <td>0.943455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION_1</th>\n",
       "      <td>1.004100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Coefficients\n",
       "MARRIAGE_0      -1.438142\n",
       "BILL_AMT1       -0.258907\n",
       "PAY_AMT1        -0.170688\n",
       "MARRIAGE_2      -0.170011\n",
       "PAY_AMT2        -0.140386\n",
       "EDUCATION_4     -0.108805\n",
       "LIMIT_BAL       -0.100438\n",
       "SEX             -0.088415\n",
       "PAY_AMT6        -0.063235\n",
       "MARRIAGE_3      -0.061553\n",
       "PAY_AMT5        -0.049132\n",
       "BILL_AMT4       -0.040800\n",
       "PAY_AMT3        -0.033158\n",
       "PAY_AMT4        -0.028955\n",
       "MARRIAGE_1      -0.027349\n",
       "PAY_6           -0.010290\n",
       "PAY_4           -0.008917\n",
       "BILL_AMT5        0.010374\n",
       "PAY_5            0.029433\n",
       "PAY_3            0.047937\n",
       "BILL_AMT6        0.057784\n",
       "BILL_AMT2        0.062594\n",
       "BILL_AMT3        0.067688\n",
       "AGE              0.070023\n",
       "PAY_2            0.100413\n",
       "PAY_0            0.496889\n",
       "EDUCATION_3      0.912959\n",
       "EDUCATION_2      0.943455\n",
       "EDUCATION_1      1.004100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coeffs = pipe_lr_opt.named_steps[\"logisticregression\"].coef_.T\n",
    "coeffs_df = pd.DataFrame(data=coeffs, index=X_train_enc.columns.tolist(), columns=[\"Coefficients\"])\n",
    "display(coeffs_df.sort_values(by=\"Coefficients\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sklearn_histGB (Optimised)</th>\n",
       "      <td>3.116090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest (Optimised)</th>\n",
       "      <td>1.976635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (Optimised)</th>\n",
       "      <td>0.233330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree (Optimised)</th>\n",
       "      <td>-0.293609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Coefficient\n",
       "sklearn_histGB (Optimised)          3.116090\n",
       "Random forest (Optimised)           1.976635\n",
       "Logistic Regression (Optimised)     0.233330\n",
       "Decision tree (Optimised)          -0.293609"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_66134/3217439548.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "classifiers = {\n",
    "    \"Random forest (Optimised)\": pipe_rf_opt,\n",
    "    \"Decision tree (Optimised)\": pipe_dt_opt,\n",
    "    \"sklearn_histGB (Optimised)\": pipe_sklearn_histGB_opt,\n",
    "    \"Logistic Regression (Optimised)\": pipe_lr_opt,\n",
    "}\n",
    "stacking_model = StackingClassifier(list(classifiers.items()))\n",
    "stacking_model.fit(X_train, y_train);\n",
    "\n",
    "# see the stacked LR's weightings\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        data=stacking_model.final_estimator_.coef_.flatten(),\n",
    "        index=classifiers.keys(),\n",
    "        columns=[\"Coefficient\"],\n",
    "    ).sort_values(\"Coefficient\", ascending=False)\n",
    ")\n",
    "\n",
    "results[\"Stacking optimized models\"] = mean_std_cross_val_scores(\n",
    "    stacking_model, X_train, y_train, return_train_score=True, scoring=scoring_metric, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random forest (Optimised)_proba</th>\n",
       "      <th>Decision tree (Optimised)_proba</th>\n",
       "      <th>sklearn_histGB (Optimised)_proba</th>\n",
       "      <th>Logistic Regression (Optimised)_proba</th>\n",
       "      <th>true_y</th>\n",
       "      <th>Stacking_predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3291</th>\n",
       "      <td>0.410549</td>\n",
       "      <td>0.410756</td>\n",
       "      <td>0.460295</td>\n",
       "      <td>0.396629</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>0.338946</td>\n",
       "      <td>0.354545</td>\n",
       "      <td>0.455670</td>\n",
       "      <td>0.463664</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12919</th>\n",
       "      <td>0.363826</td>\n",
       "      <td>0.354545</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.596713</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>0.303162</td>\n",
       "      <td>0.209391</td>\n",
       "      <td>0.310380</td>\n",
       "      <td>0.237717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16210</th>\n",
       "      <td>0.890081</td>\n",
       "      <td>0.912256</td>\n",
       "      <td>0.896120</td>\n",
       "      <td>0.835846</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24769</th>\n",
       "      <td>0.730663</td>\n",
       "      <td>0.706422</td>\n",
       "      <td>0.741143</td>\n",
       "      <td>0.787256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20121</th>\n",
       "      <td>0.239426</td>\n",
       "      <td>0.209391</td>\n",
       "      <td>0.244851</td>\n",
       "      <td>0.530276</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22973</th>\n",
       "      <td>0.382100</td>\n",
       "      <td>0.354545</td>\n",
       "      <td>0.462882</td>\n",
       "      <td>0.604417</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21315</th>\n",
       "      <td>0.494852</td>\n",
       "      <td>0.410756</td>\n",
       "      <td>0.565399</td>\n",
       "      <td>0.353335</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19585</th>\n",
       "      <td>0.265375</td>\n",
       "      <td>0.209391</td>\n",
       "      <td>0.299643</td>\n",
       "      <td>0.387742</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Random forest (Optimised)_proba  Decision tree (Optimised)_proba  \\\n",
       "ID                                                                        \n",
       "3291                          0.410549                         0.410756   \n",
       "4652                          0.338946                         0.354545   \n",
       "12919                         0.363826                         0.354545   \n",
       "1005                          0.303162                         0.209391   \n",
       "16210                         0.890081                         0.912256   \n",
       "24769                         0.730663                         0.706422   \n",
       "20121                         0.239426                         0.209391   \n",
       "22973                         0.382100                         0.354545   \n",
       "21315                         0.494852                         0.410756   \n",
       "19585                         0.265375                         0.209391   \n",
       "\n",
       "       sklearn_histGB (Optimised)_proba  \\\n",
       "ID                                        \n",
       "3291                           0.460295   \n",
       "4652                           0.455670   \n",
       "12919                          0.415300   \n",
       "1005                           0.310380   \n",
       "16210                          0.896120   \n",
       "24769                          0.741143   \n",
       "20121                          0.244851   \n",
       "22973                          0.462882   \n",
       "21315                          0.565399   \n",
       "19585                          0.299643   \n",
       "\n",
       "       Logistic Regression (Optimised)_proba  true_y  Stacking_predict  \n",
       "ID                                                                      \n",
       "3291                                0.396629       1                 0  \n",
       "4652                                0.463664       1                 0  \n",
       "12919                               0.596713       1                 0  \n",
       "1005                                0.237717       1                 0  \n",
       "16210                               0.835846       1                 1  \n",
       "24769                               0.787256       1                 1  \n",
       "20121                               0.530276       1                 0  \n",
       "22973                               0.604417       1                 0  \n",
       "21315                               0.353335       1                 0  \n",
       "19585                               0.387742       1                 0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter to all rows where y == 1, see soft proba for a sample dataset\n",
    "train_df = train_df.rename(columns={'default.payment.next.month': 'y'}) #cannot have '.' in  name\n",
    "test_yeq1_df = (\n",
    "    train_df.query(\"y == 1\")\n",
    "    .sample(10, random_state=76)\n",
    ")\n",
    "\n",
    "test_yeq1_x = test_yeq1_df.drop(columns=[\"y\"])\n",
    "test_yeq1_y = test_yeq1_df[\"y\"]\n",
    "\n",
    "data = {\n",
    "    name + \"_proba\": pipe.predict_proba(test_yeq1_x)[:, 1]\n",
    "    for (name, pipe) in stacking_model.named_estimators_.items()\n",
    "}\n",
    "data['true_y'] = test_yeq1_y  \n",
    "data['Stacking_predict'] = stacking_model.predict(test_yeq1_x)\n",
    "display(pd.DataFrame(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # see the stacked LR's weightings\n",
    "# pd.DataFrame(\n",
    "#     data=stacking_model.final_estimator_.coef_.flatten(),\n",
    "#     index=classifiers.keys(),\n",
    "#     columns=[\"Coefficient\"],\n",
    "# ).sort_values(\"Coefficient\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random forest (Optimised)</th>\n",
       "      <td>7.710 (+/- 2.506)</td>\n",
       "      <td>0.089 (+/- 0.019)</td>\n",
       "      <td>0.794 (+/- 0.004)</td>\n",
       "      <td>0.802 (+/- 0.001)</td>\n",
       "      <td>0.535 (+/- 0.009)</td>\n",
       "      <td>0.552 (+/- 0.002)</td>\n",
       "      <td>0.541 (+/- 0.022)</td>\n",
       "      <td>0.559 (+/- 0.006)</td>\n",
       "      <td>0.538 (+/- 0.012)</td>\n",
       "      <td>0.556 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn_histGB (Optimised)</th>\n",
       "      <td>1.035 (+/- 0.200)</td>\n",
       "      <td>0.025 (+/- 0.003)</td>\n",
       "      <td>0.779 (+/- 0.006)</td>\n",
       "      <td>0.802 (+/- 0.004)</td>\n",
       "      <td>0.502 (+/- 0.012)</td>\n",
       "      <td>0.547 (+/- 0.007)</td>\n",
       "      <td>0.579 (+/- 0.018)</td>\n",
       "      <td>0.635 (+/- 0.006)</td>\n",
       "      <td>0.538 (+/- 0.012)</td>\n",
       "      <td>0.587 (+/- 0.006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree (Optimised)</th>\n",
       "      <td>0.259 (+/- 0.032)</td>\n",
       "      <td>0.021 (+/- 0.003)</td>\n",
       "      <td>0.783 (+/- 0.010)</td>\n",
       "      <td>0.792 (+/- 0.009)</td>\n",
       "      <td>0.511 (+/- 0.021)</td>\n",
       "      <td>0.530 (+/- 0.019)</td>\n",
       "      <td>0.539 (+/- 0.018)</td>\n",
       "      <td>0.558 (+/- 0.021)</td>\n",
       "      <td>0.524 (+/- 0.012)</td>\n",
       "      <td>0.543 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking optimized models</th>\n",
       "      <td>155.423 (+/- 0.248)</td>\n",
       "      <td>0.356 (+/- 0.054)</td>\n",
       "      <td>0.820 (+/- 0.005)</td>\n",
       "      <td>0.827 (+/- 0.002)</td>\n",
       "      <td>0.663 (+/- 0.019)</td>\n",
       "      <td>0.688 (+/- 0.009)</td>\n",
       "      <td>0.386 (+/- 0.017)</td>\n",
       "      <td>0.401 (+/- 0.003)</td>\n",
       "      <td>0.488 (+/- 0.016)</td>\n",
       "      <td>0.506 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>2.469 (+/- 1.537)</td>\n",
       "      <td>0.155 (+/- 0.287)</td>\n",
       "      <td>0.817 (+/- 0.008)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "      <td>0.653 (+/- 0.031)</td>\n",
       "      <td>0.999 (+/- 0.000)</td>\n",
       "      <td>0.376 (+/- 0.024)</td>\n",
       "      <td>0.999 (+/- 0.000)</td>\n",
       "      <td>0.477 (+/- 0.026)</td>\n",
       "      <td>0.999 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn_histGB</th>\n",
       "      <td>1.607 (+/- 0.471)</td>\n",
       "      <td>0.062 (+/- 0.069)</td>\n",
       "      <td>0.820 (+/- 0.007)</td>\n",
       "      <td>0.834 (+/- 0.004)</td>\n",
       "      <td>0.673 (+/- 0.027)</td>\n",
       "      <td>0.726 (+/- 0.017)</td>\n",
       "      <td>0.370 (+/- 0.022)</td>\n",
       "      <td>0.403 (+/- 0.010)</td>\n",
       "      <td>0.477 (+/- 0.023)</td>\n",
       "      <td>0.518 (+/- 0.012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (Optimised)</th>\n",
       "      <td>0.218 (+/- 0.025)</td>\n",
       "      <td>0.020 (+/- 0.001)</td>\n",
       "      <td>0.509 (+/- 0.011)</td>\n",
       "      <td>0.510 (+/- 0.002)</td>\n",
       "      <td>0.281 (+/- 0.006)</td>\n",
       "      <td>0.282 (+/- 0.001)</td>\n",
       "      <td>0.780 (+/- 0.013)</td>\n",
       "      <td>0.784 (+/- 0.002)</td>\n",
       "      <td>0.414 (+/- 0.007)</td>\n",
       "      <td>0.415 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.724 (+/- 0.178)</td>\n",
       "      <td>0.025 (+/- 0.011)</td>\n",
       "      <td>0.723 (+/- 0.010)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "      <td>0.385 (+/- 0.020)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "      <td>0.417 (+/- 0.030)</td>\n",
       "      <td>0.998 (+/- 0.000)</td>\n",
       "      <td>0.400 (+/- 0.024)</td>\n",
       "      <td>0.999 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.190 (+/- 0.016)</td>\n",
       "      <td>0.019 (+/- 0.001)</td>\n",
       "      <td>0.810 (+/- 0.007)</td>\n",
       "      <td>0.811 (+/- 0.001)</td>\n",
       "      <td>0.714 (+/- 0.042)</td>\n",
       "      <td>0.719 (+/- 0.005)</td>\n",
       "      <td>0.238 (+/- 0.025)</td>\n",
       "      <td>0.240 (+/- 0.004)</td>\n",
       "      <td>0.357 (+/- 0.033)</td>\n",
       "      <td>0.359 (+/- 0.005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.172 (+/- 0.123)</td>\n",
       "      <td>0.060 (+/- 0.056)</td>\n",
       "      <td>0.778 (+/- 0.000)</td>\n",
       "      <td>0.778 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            fit_time         score_time  \\\n",
       "Random forest (Optimised)          7.710 (+/- 2.506)  0.089 (+/- 0.019)   \n",
       "sklearn_histGB (Optimised)         1.035 (+/- 0.200)  0.025 (+/- 0.003)   \n",
       "Decision tree (Optimised)          0.259 (+/- 0.032)  0.021 (+/- 0.003)   \n",
       "Stacking optimized models        155.423 (+/- 0.248)  0.356 (+/- 0.054)   \n",
       "Random forest                      2.469 (+/- 1.537)  0.155 (+/- 0.287)   \n",
       "sklearn_histGB                     1.607 (+/- 0.471)  0.062 (+/- 0.069)   \n",
       "Logistic Regression (Optimised)    0.218 (+/- 0.025)  0.020 (+/- 0.001)   \n",
       "Decision tree                      0.724 (+/- 0.178)  0.025 (+/- 0.011)   \n",
       "Logistic Regression                0.190 (+/- 0.016)  0.019 (+/- 0.001)   \n",
       "Dummy                              0.172 (+/- 0.123)  0.060 (+/- 0.056)   \n",
       "\n",
       "                                     test_accuracy     train_accuracy  \\\n",
       "Random forest (Optimised)        0.794 (+/- 0.004)  0.802 (+/- 0.001)   \n",
       "sklearn_histGB (Optimised)       0.779 (+/- 0.006)  0.802 (+/- 0.004)   \n",
       "Decision tree (Optimised)        0.783 (+/- 0.010)  0.792 (+/- 0.009)   \n",
       "Stacking optimized models        0.820 (+/- 0.005)  0.827 (+/- 0.002)   \n",
       "Random forest                    0.817 (+/- 0.008)  1.000 (+/- 0.000)   \n",
       "sklearn_histGB                   0.820 (+/- 0.007)  0.834 (+/- 0.004)   \n",
       "Logistic Regression (Optimised)  0.509 (+/- 0.011)  0.510 (+/- 0.002)   \n",
       "Decision tree                    0.723 (+/- 0.010)  1.000 (+/- 0.000)   \n",
       "Logistic Regression              0.810 (+/- 0.007)  0.811 (+/- 0.001)   \n",
       "Dummy                            0.778 (+/- 0.000)  0.778 (+/- 0.000)   \n",
       "\n",
       "                                    test_precision    train_precision  \\\n",
       "Random forest (Optimised)        0.535 (+/- 0.009)  0.552 (+/- 0.002)   \n",
       "sklearn_histGB (Optimised)       0.502 (+/- 0.012)  0.547 (+/- 0.007)   \n",
       "Decision tree (Optimised)        0.511 (+/- 0.021)  0.530 (+/- 0.019)   \n",
       "Stacking optimized models        0.663 (+/- 0.019)  0.688 (+/- 0.009)   \n",
       "Random forest                    0.653 (+/- 0.031)  0.999 (+/- 0.000)   \n",
       "sklearn_histGB                   0.673 (+/- 0.027)  0.726 (+/- 0.017)   \n",
       "Logistic Regression (Optimised)  0.281 (+/- 0.006)  0.282 (+/- 0.001)   \n",
       "Decision tree                    0.385 (+/- 0.020)  1.000 (+/- 0.000)   \n",
       "Logistic Regression              0.714 (+/- 0.042)  0.719 (+/- 0.005)   \n",
       "Dummy                            0.000 (+/- 0.000)  0.000 (+/- 0.000)   \n",
       "\n",
       "                                       test_recall       train_recall  \\\n",
       "Random forest (Optimised)        0.541 (+/- 0.022)  0.559 (+/- 0.006)   \n",
       "sklearn_histGB (Optimised)       0.579 (+/- 0.018)  0.635 (+/- 0.006)   \n",
       "Decision tree (Optimised)        0.539 (+/- 0.018)  0.558 (+/- 0.021)   \n",
       "Stacking optimized models        0.386 (+/- 0.017)  0.401 (+/- 0.003)   \n",
       "Random forest                    0.376 (+/- 0.024)  0.999 (+/- 0.000)   \n",
       "sklearn_histGB                   0.370 (+/- 0.022)  0.403 (+/- 0.010)   \n",
       "Logistic Regression (Optimised)  0.780 (+/- 0.013)  0.784 (+/- 0.002)   \n",
       "Decision tree                    0.417 (+/- 0.030)  0.998 (+/- 0.000)   \n",
       "Logistic Regression              0.238 (+/- 0.025)  0.240 (+/- 0.004)   \n",
       "Dummy                            0.000 (+/- 0.000)  0.000 (+/- 0.000)   \n",
       "\n",
       "                                           test_f1           train_f1  \n",
       "Random forest (Optimised)        0.538 (+/- 0.012)  0.556 (+/- 0.003)  \n",
       "sklearn_histGB (Optimised)       0.538 (+/- 0.012)  0.587 (+/- 0.006)  \n",
       "Decision tree (Optimised)        0.524 (+/- 0.012)  0.543 (+/- 0.003)  \n",
       "Stacking optimized models        0.488 (+/- 0.016)  0.506 (+/- 0.003)  \n",
       "Random forest                    0.477 (+/- 0.026)  0.999 (+/- 0.000)  \n",
       "sklearn_histGB                   0.477 (+/- 0.023)  0.518 (+/- 0.012)  \n",
       "Logistic Regression (Optimised)  0.414 (+/- 0.007)  0.415 (+/- 0.001)  \n",
       "Decision tree                    0.400 (+/- 0.024)  0.999 (+/- 0.000)  \n",
       "Logistic Regression              0.357 (+/- 0.033)  0.359 (+/- 0.005)  \n",
       "Dummy                            0.000 (+/- 0.000)  0.000 (+/- 0.000)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorting values in order of validation F1-score\n",
    "pd.DataFrame(results).T.sort_values('test_f1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 9. Results on the test set <a name=\"12\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 10_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try your best performing model on the test data: report and explain test scores.\n",
    "2. Do the test scores agree with the validation scores from before? To what extent do you trust your results? Do you think you've had issues with optimization bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_9\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)\n",
    "\n",
    "Under the assumption that the F1-score test metric provides the most information about the quality of the model, while mitigating the confusion from class imbalance, we have selected the model with the greatest cross-validation F1-score as our best performing model. Given the above results table, we believe that the optimised random forest had the best overall performance. \n",
    "\n",
    "(2)\n",
    "\n",
    "Due to the varying models that have been trained, along with the hyperparameter optimisations performed for them, we can trust these results to a reasonable degree. However, there is almost certainly a much more complicated model out there that could yield better results, such as averaging or stacking classifiers, though the extra amount of time required for such may not be worth the improvement of results.\n",
    "\n",
    "Optimisation bias could have come into play to a small extent. However, for optimisation bias to be a significant problem, we would have had to use the validation set many times and have little training data. The dataset used has 30,000 entries, and thus has a minimal risk of optimisation bias. When optimising hyperparameters, only approximately five or so values for each parameter have been searched over, and thus we believe it is generalisable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_66134/3217439548.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fit_time          16.981 (+/- 5.447)\n",
       "score_time         0.101 (+/- 0.035)\n",
       "test_accuracy      0.796 (+/- 0.010)\n",
       "test_precision     0.534 (+/- 0.022)\n",
       "test_recall        0.544 (+/- 0.030)\n",
       "test_f1            0.539 (+/- 0.023)\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rf_opt.fit(X_train, y_train)\n",
    "scores = mean_std_cross_val_scores(pipe_rf_opt, X_test, y_test, cv=10, scoring=scoring_metric, n_jobs=-1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 10. Summary of results <a name=\"13\"></a>\n",
    "<hr>\n",
    "\n",
    "_points 12_\n",
    "\n",
    "Imagine that you want to present the summary of these results to your boss and co-workers. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a table (printed `DataFrame`) summarizing important results. \n",
    "2. Write concluding remarks.\n",
    "3. Discuss other ideas that you did not try but could potentially improve the performance/interpretability . \n",
    "3. Report your final test score along with the metric you used at the top of this notebook in the [Submission instructions section](#si)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_10\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) After working with a variety of models and tuning their hyperparameters of interest, we have concluded that, in this case, the random forest classifier is the most effective for maximizing the F1 score of this dataset. The optimal parameters we have found include 400 estimators, 20 features, a maximum depth of 5, and a class weight ratio of 1:3.\n",
    "\n",
    "(3) Combining existing models, such as averaging and stacking, could have been implemented. We could also consider using different scoring metrics instead of just the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY OF RESULTS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>16.981 (+/- 5.447)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.101 (+/- 0.035)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.796 (+/- 0.010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.534 (+/- 0.022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.544 (+/- 0.030)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.539 (+/- 0.023)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_model</th>\n",
       "      <td>Random forest (Optimised)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier__n_estimators</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier__max_features</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier__max_depth</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforestclassifier__class_weight</th>\n",
       "      <td>{0: 1, 1: 3}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               \n",
       "fit_time                                     16.981 (+/- 5.447)\n",
       "score_time                                    0.101 (+/- 0.035)\n",
       "test_accuracy                                 0.796 (+/- 0.010)\n",
       "test_precision                                0.534 (+/- 0.022)\n",
       "test_recall                                   0.544 (+/- 0.030)\n",
       "test_f1                                       0.539 (+/- 0.023)\n",
       "best_model                            Random forest (Optimised)\n",
       "randomforestclassifier__n_estimators                        400\n",
       "randomforestclassifier__max_features                         20\n",
       "randomforestclassifier__max_depth                             5\n",
       "randomforestclassifier__class_weight               {0: 1, 1: 3}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (1)\n",
    "scores['best_model'] = 'Random forest (Optimised)'\n",
    "# convert the dictionary to a Series\n",
    "best_params_rf_series = pd.Series(best_params_rf)\n",
    "\n",
    "# concatenate the Series and the dictionary\n",
    "summary = pd.concat([scores, best_params_rf_series])\n",
    "print(\"SUMMARY OF RESULTS\")\n",
    "display(summary.to_frame(''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using PrairieLearn.\n",
    "4. Make sure that the plots and output are rendered properly in your submitted file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a tricky one but you did it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
